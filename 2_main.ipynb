{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_dir: /home/yishai/Desktop/ivrit_ai_llm/app\n",
      "data_dir: /home/yishai/Desktop/ivrit_ai_llm/data\n",
      "golden_data_dir: /home/yishai/Desktop/ivrit_ai_llm/golden_data\n"
     ]
    }
   ],
   "source": [
    "from app.dotenv import base_dir, data_dir,golden_data_dir\n",
    "# from app.model.model import  Model\n",
    "# import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)\n",
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "# print('dotenv params:', {os.getenv('PARAM1')})\n",
    "print('base_dir:', base_dir)\n",
    "print('data_dir:', data_dir)\n",
    "print('golden_data_dir:', golden_data_dir)\n",
    "\n",
    "# model = Model()\n",
    "# print('model:', model)\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avg_logprob - the average log probability of the tokens in the transcription\n",
    "estimating the confidence of the transcription. Lower values (more negative) indicate lower confidence, while values closer to zero indicate higher confidence in the transcription.\n",
    "Values generally range between -1.0 and 0, below -0.5 is suspected below -1 is very suspected\n",
    "\n",
    "\n",
    "no_speech_prob - probability is high (close to 1), it suggests that the model believes the segment is likely silence or background noise, rather than actual speech. This can be useful for filtering out non-speech parts.\n",
    "Values range from 0 to 1, where 0 indicates a high likelihood that the segment contains speech, and 1 indicates a high probability that the segment contains no speech.\n",
    "\n",
    "compression_ratio - measure of how much the output text has been \"compressed\" compared to the input audio in terms of information content. Higher values might indicate potential issues, such as long stretches of repeated text or overly verbose output.\n",
    "Typically ranges from 1.0 to 2.5. A value of 1.0 means that the transcription is roughly equal in length to the original audio input, while higher values indicate more compression (shorter transcribed text relative to the audio duration).\n",
    "\n",
    "Suggested Workflow:\n",
    "\n",
    "Filter Low Confidence Segments: Identify segments with a low avg_logprob or a high no_speech_prob and prioritize these for refinement by the LLM.\n",
    "\n",
    "Fix Repetitive or Garbled Transcriptions: Use the compression_ratio to detect where the transcribed text might be problematic (too verbose, repeated words) and ask the LLM to clean up these sections.\n",
    "\n",
    "Time-based Post-Processing: Use the start and end timestamps to make sure the LLM processes segments in the right sequence, especially if you are breaking up the transcription for batch processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load df from file\n",
    "\n",
    "1. add wanted attribute columns & remove nulls  \n",
    "2. drop columns\n",
    "3. remove formatting chracters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{golden_data_dir}/crowd-transcribe-v4-enriched.csv')\n",
    "ind = ~df['attrs'].isnull()\n",
    "df.loc[ind,'attrs'] = df.loc[ind,'attrs'].apply(lambda x: json.loads(x))\n",
    "df = df.loc[((~df['sentence'].isnull())*(~df['orig_sentence'].isnull()))]\n",
    "# verify nulls are dropped\n",
    "# df['sentence'].loc[(~(~df['sentence'].isnull())*(~df['orig_sentence'].isnull()))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111858\n",
      "1901\n",
      "5307\n"
     ]
    }
   ],
   "source": [
    "vals = {'avg_logprob':-0.5,'no_speech_prob':0.5,'compression_ratio':2.0}\n",
    "inds = {}\n",
    "for key,value in vals.items():\n",
    "    df[key] = value\n",
    "    # df.loc[0,'attrs']['segments'][0]['avg_logprob']\n",
    "    df[key] = None\n",
    "    df.loc[ind,key] = df.loc[ind,'attrs'].apply( lambda x:  x['segments'][0][key] )\n",
    "    # data = df.loc[ind,key].loc[df.loc[ind,key]>value]\n",
    "    inds[key] = (df.loc[ind,key].loc[df.loc[ind,key]>value].index,df.loc[ind,key].loc[df.loc[ind,key]<value].index)    \n",
    "    print(len(inds[key][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orig_sentence', 'sentence', 'source', 'episode', 'avg_logprob',\n",
       "       'no_speech_prob', 'compression_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['attrs','is_retranscribe','uuid'],inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove formatting chracters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing chars and their ords\n",
      " ,\t!,\t\",\t$,\t%,\t&,\t',\t(,\t),\t+,\t,,\t-,\t.,\t0,\t1,\t2,\t3,\t4,\t5,\t6,\t7,\t8,\t9,\t:,\t=,\t?,\t[,\t],\ta,\tb,\tc,\td,\te,\tf,\tg,\th,\ti,\tj,\tk,\tl,\tm,\tn,\to,\tp,\tq,\tr,\ts,\tt,\tu,\tv,\tw,\tx,\ty,\tz,\tא,\tב,\tג,\tד,\tה,\tו,\tז,\tח,\tט,\tי,\tך,\tכ,\tל,\tם,\tמ,\tן,\tנ,\tס,\tע,\tף,\tפ,\tץ,\tצ,\tק,\tר,\tש,\tת,\n",
      "32,\t33,\t34,\t36,\t37,\t38,\t39,\t40,\t41,\t43,\t44,\t45,\t46,\t48,\t49,\t50,\t51,\t52,\t53,\t54,\t55,\t56,\t57,\t58,\t61,\t63,\t91,\t93,\t97,\t98,\t99,\t100,\t101,\t102,\t103,\t104,\t105,\t106,\t107,\t108,\t109,\t110,\t111,\t112,\t113,\t114,\t115,\t116,\t117,\t118,\t119,\t120,\t121,\t122,\t1488,\t1489,\t1490,\t1491,\t1492,\t1493,\t1494,\t1495,\t1496,\t1497,\t1498,\t1499,\t1500,\t1501,\t1502,\t1503,\t1504,\t1505,\t1506,\t1507,\t1508,\t1509,\t1510,\t1511,\t1512,\t1513,\t1514,\n"
     ]
    }
   ],
   "source": [
    "def remove_error_chars(df: DataFrame,columns,) -> DataFrame:\n",
    "    remove_ords1 = [1470,1468,1465,1463,1462,1460,1099,1464,47,1523,\t1524,\t1575,\t1576,\t1578,\t1582,\t1585,\t1603,\t1606,\t8211,\t8212,\t8230,\t9834,\t9835,\t20126,\t21478,\t24555,\t26126,\t26449,\t27794,\t29978,\t35201,\t38590,\t40636,\t46988,\t47673,\t49324,\t49900,\t50508,\t50520,\t50612,\t50880,\t51032,\t51060,\t65533,]\n",
    "    # latin letters - might be usefull to keep\n",
    "    remove_ords2 = [380,\t945,\t950,\t956,\t959,\t960,\t1072,\t1073,\t1074,\t1075,\t1076,\t1077,\t1080,\t1082,\t1083,\t1086,\t1087,\t1088,\t1089,\t1091,\t1096,\t1100]\n",
    "    remove_chars = ['\\u202b','\\u200f','\\u200e','\\n']\n",
    "    # ords_to_replace = [32,45]\n",
    "    def replace_chars_from_col(col,in_chars,replace_char = '',is_ord = False):\n",
    "        for ch in in_chars:\n",
    "            if is_ord:\n",
    "                col = col.str.replace(chr(ch),replace_char)\n",
    "            else:\n",
    "                col = col.str.replace(ch,replace_char)\n",
    "            \n",
    "        # for ch in ['  ','-']:\n",
    "        #     col = col.str.replace(ch,' ')\n",
    "        return col\n",
    "\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].str.lower()\n",
    "        df[col] = replace_chars_from_col(df[col].copy(),remove_ords1,replace_char = '',is_ord = True)\n",
    "        df[col] = replace_chars_from_col(df[col].copy(),remove_ords2,replace_char = '',is_ord = True)\n",
    "\n",
    "        df[col] = replace_chars_from_col(df[col].copy(),remove_chars,replace_char = '',is_ord = False)\n",
    "    return df\n",
    "\n",
    "def cols_unique_characters(cols,print_ord = False):\n",
    "    uniq_chars = sorted(set(''.join(''.join(col) for col in cols)))\n",
    "    if print_ord:\n",
    "        return [ord(ch) for ch in uniq_chars]\n",
    "    return uniq_chars\n",
    "\n",
    "\n",
    "def print_existing_unique_chars(cols):\n",
    "    \n",
    "    uniq1 = cols_unique_characters(cols)\n",
    "    uniq2 = cols_unique_characters(cols,print_ord = True)\n",
    "    print ('existing chars and their ords') \n",
    "    print('\\t'.join([str(x)+',' for x in uniq1]))\n",
    "    print('\\t'.join([str(x)+',' for x in uniq2]))\n",
    "    \n",
    "    \n",
    "df = remove_error_chars(df.copy(),columns = ['orig_sentence','sentence'])    \n",
    "print_existing_unique_chars([df['orig_sentence'].copy(),df['orig_sentence'].copy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analyisis\n",
    "\n",
    "1. seperate data into seperate words (remove formatting)\n",
    "2. find the hebrew words errors\n",
    "3. find the errors location in original df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seperate data into seperate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(all_data_string):#just for testing they are not errors\n",
    "    ord_special_chars = [32,\t33,\t34,\t36,\t37,\t38,\t39,\t40,\t41,\t43,\t44,\t45,\t46,58,\t61,\t63,\t91,\t93,]\n",
    "    # ord_english_chars = \n",
    "    # for ch in [',','.',\"'\",'\"','?','{','}','[',']','(',')','—', '…','!','&']:#,'\\\\','`','*','_',,'>','<','^','#',':',';','+','-','.',,'@','%',,'$','?','\\'','\"','\\u202b',,'♪', '♫',r'\\u200']:\n",
    "    # [',','\\\\','`','*','_','{','}','[',']','(',')','>','<','^','#',':',';','+','-','.','!','@','%','&','$','?','\\'','\"','\\u202b','—', '…','♪', '♫',r'\\u200']:\n",
    "    for ord_ in ord_special_chars:  \n",
    "        all_data_string = all_data_string.replace(chr(ord_),' ')\n",
    "    # for ch in ['  ','-']:\n",
    "    # col = col.str.replace('  ',' ')\n",
    "    \n",
    "    # s = pd.to_numeric(col,errors='coerce')\n",
    "    # col = col.loc[~s.notna()]\n",
    "    return all_data_string\n",
    "def remove_numbers(uniq):\n",
    "    return [x for x in uniq if not x.isnumeric()]\n",
    "def df_unique_words(col):\n",
    "    joined = ' '.join(col)\n",
    "    joined = remove_special_chars(joined)\n",
    "    uniq =  sorted(list(set(joined.split(' '))))\n",
    "    uniq = remove_numbers(uniq)\n",
    "    \n",
    "    \n",
    "    return uniq\n",
    "unique_words = df_unique_words(df['orig_sentence'].copy().tolist())\n",
    "# uniq = df_unique_words(uniq)\n",
    "# uniq = df_unique_words(uniq)\n",
    "# print(uniq)\n",
    "# uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def find_hebrew_words(uniq):\n",
    "    hebrew_words = [word for word in uniq if any(ord(ch)>1487 for ch in word)]\n",
    "    return hebrew_words\n",
    "\n",
    "def find_error_words(hebrew_words):\n",
    "    end_letters = set([1509,1507,1503,1501])\n",
    "    english_letters = set(range(97,123))\n",
    "    # todo: verbs mixup (aleph vs ayin)\n",
    "    # todo: compare to dictionairy\n",
    "    # todo: words with foreign letters  - (might be translated fonetically)\n",
    "    # todo: words with numbers\n",
    "    # todo: words with special characters\n",
    "    \n",
    "    \n",
    "    \n",
    "    error_words1 = [word for word in hebrew_words if any(ord(ch) in end_letters for ch in word[:-1])]\n",
    "    error_words2 = [word for word in hebrew_words if any(ord(ch) in english_letters for ch in word)]\n",
    "    return error_words1 + error_words2\n",
    "hebrew_words = find_hebrew_words(unique_words)\n",
    "errors = find_error_words(hebrew_words)\n",
    "# errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_error_words_df_location(col,errors):\n",
    "    # errors_set = set(errors)\n",
    "    \n",
    "    error_location = {}\n",
    "    for error in errors:\n",
    "        ind = col.str.contains(error)\n",
    "        error_location[error] = df.loc[ind].index.tolist()\n",
    "        \n",
    "    return error_location\n",
    "\n",
    "error_location = find_error_words_df_location(df['orig_sentence'].copy(),errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 28705, 32506, 28808, 29112, 34397, 34351, 28804]\n",
      "<s> שלום!מהשלמהיום?\n",
      "['<s>', '▁', 'שלום', '!', 'מ', 'השל', 'מהיום', '?']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yam-peleg/Hebrew-Mistral-7B-200K\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"yam-peleg/Hebrew-Mistral-7B-200K\")\n",
    "\n",
    "text = \"שלום!מהשלמהיום?\"\n",
    "# input_ids = tokenizer(text, return_tensors=\"pt\")#.to(\"cuda\")\n",
    "# print(input_ids)\n",
    "tokens = tokenizer(text )\n",
    "print(tokens['input_ids'])  \n",
    "decoded_text = tokenizer.decode(tokens['input_ids'])\n",
    "print(decoded_text)  \n",
    "\n",
    "encoded_text = tokenizer.convert_ids_to_tokens(tokens['input_ids'])\n",
    "\n",
    "# Print the tokens\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bert score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dicta-il/dictabert\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"dicta-il/dictabert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "התמחותו\n",
      "מחקרו\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('dicta-il/dictabert')\n",
    "model = AutoModelForMaskedLM.from_pretrained('dicta-il/dictabert')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "sentence = 'בשנת 1948 השלים אפרים קישון את [MASK] בפיסול מתכת ובתולדות האמנות והחל לפרסם מאמרים הומוריסטיים'\n",
    "\n",
    "output = model(tokenizer.encode(sentence, return_tensors='pt'))\n",
    "# the [MASK] is the 7th token (including [CLS])\n",
    "import torch\n",
    "top_2 = torch.topk(output.logits[0, 7, :], 2)[1]\n",
    "print('\\n'.join(tokenizer.convert_ids_to_tokens(top_2))) # should print מחקרו / התמחותו "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a323bca742e448159f3955635d790f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c38af0d0a14658b82f63b629442d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1381eca00f45438e5f580dfab4bfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f169caeafc140228aea13cc521e4c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yishai/Desktop/ivrit_ai_llm/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a140f1a9204453e9d78da5e6d8eb46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.9258, Recall: 0.9258, F1: 0.9258\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
    "from bert_score import BERTScorer\n",
    "\n",
    "# Example texts\n",
    "reference = \"This is a reference text example.\"\n",
    "candidate = \"This is a candidate text example.\"\n",
    "# BERTScore calculation\n",
    "scorer = BERTScorer(model_type='bert-base-uncased')\n",
    "P, R, F1 = scorer.score([candidate], [reference])\n",
    "print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# from bert_score import BERTScorer\n",
    "\n",
    "# # Load the tokenizer for the Hebrew BERT model\n",
    "# model_name = 'dicta-il/dictabert'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Example texts (in Hebrew)\n",
    "# reference = \"הטקסט הזה הוא דוגמה של טקסט התייחסות.\"\n",
    "# candidate = \"הטקסט הזה הוא דוגמה של טקסט מועמד.\"\n",
    "\n",
    "# # BERTScore calculation\n",
    "# scorer = BERTScorer(model_type=model_name, tokenizer=tokenizer)\n",
    "# P, R, F1 = scorer.score([candidate], [reference])\n",
    "\n",
    "# print(f\"BERTScore Precision: {P.mean():.4f}, Recall: {R.mean():.4f}, F1: {F1.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dicta-il/dictabert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Similarity: 0.8770157694816589\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the Hebrew BERT model and tokenizer\n",
    "model_name = 'dicta-il/dictabert'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to get embeddings for a list of sentences\n",
    "def get_embeddings(sentences):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Tokenize the input sentences\n",
    "        inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "        # Get the embeddings\n",
    "        outputs = model(**inputs)\n",
    "        # Use the mean of the hidden states as the sentence embeddings\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Define the reference and candidate sentences\n",
    "reference_sentence = 'הטקסט המדויק הזה הוא המושלם.'\n",
    "candidate_sentence = 'המשפט הזה הוא הטוב ביותר.'\n",
    "\n",
    "# Get embeddings for the sentences\n",
    "reference_embedding = get_embeddings([reference_sentence])\n",
    "candidate_embedding = get_embeddings([candidate_sentence])\n",
    "\n",
    "# Calculate cosine similarity between embeddings\n",
    "similarity = cosine_similarity(reference_embedding, candidate_embedding)\n",
    "print(f\"BERTScore Similarity: {similarity[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dicta-il/dictabert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore Precision: 0.8445, Recall: 0.8345, F1: 0.8395\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the Hebrew BERT model and tokenizer\n",
    "model_name = 'dicta-il/dictabert'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to get token embeddings for a list of sentences\n",
    "def get_token_embeddings(sentences):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Tokenize the input sentences\n",
    "        inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "        # Get the embeddings\n",
    "        outputs = model(**inputs)\n",
    "        # Get the embeddings for all tokens\n",
    "        embeddings = outputs.last_hidden_state\n",
    "    return embeddings\n",
    "\n",
    "# Compute BERTScore Precision, Recall, and F1\n",
    "def compute_bert_score(reference, candidate):\n",
    "    ref_embeddings = get_token_embeddings([reference])\n",
    "    cand_embeddings = get_token_embeddings([candidate])\n",
    "    \n",
    "    # Compute cosine similarities between each token in the candidate and reference\n",
    "    ref_tokens = tokenizer(reference, return_tensors='pt')['input_ids'].squeeze().tolist()\n",
    "    cand_tokens = tokenizer(candidate, return_tensors='pt')['input_ids'].squeeze().tolist()\n",
    "    \n",
    "    ref_embeddings = ref_embeddings.squeeze(0)\n",
    "    cand_embeddings = cand_embeddings.squeeze(0)\n",
    "    \n",
    "    # Token-level similarity matrix\n",
    "    similarity_matrix = cosine_similarity(cand_embeddings.numpy(), ref_embeddings.numpy())\n",
    "    \n",
    "    # Compute precision\n",
    "    precision_scores = []\n",
    "    for i, cand_token in enumerate(cand_tokens):\n",
    "        cand_emb = cand_embeddings[i].unsqueeze(0).numpy()\n",
    "        similarities = similarity_matrix[i]\n",
    "        max_similarity = max(similarities)\n",
    "        precision_scores.append(max_similarity)\n",
    "    \n",
    "    precision = np.mean(precision_scores)\n",
    "    \n",
    "    # Compute recall\n",
    "    recall_scores = []\n",
    "    for j, ref_token in enumerate(ref_tokens):\n",
    "        ref_emb = ref_embeddings[j].unsqueeze(0).numpy()\n",
    "        similarities = similarity_matrix[:, j]\n",
    "        max_similarity = max(similarities)\n",
    "        recall_scores.append(max_similarity)\n",
    "    \n",
    "    recall = np.mean(recall_scores)\n",
    "    \n",
    "    # F1 score as the harmonic mean of precision and recall\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0.0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Define the reference and candidate sentences in Hebrew\n",
    "reference_sentence = 'הטקסט המדויק הזה הוא המושלם.'\n",
    "candidate_sentence = 'המשפט הזה הוא הטוב ביותר.'\n",
    "\n",
    "# Compute BERTScore\n",
    "precision, recall, f1 = compute_bert_score(reference_sentence, candidate_sentence)\n",
    "\n",
    "# Print BERTScore Precision, Recall, and F1\n",
    "print(f\"BERTScore Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morig_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_orig\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_orig\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muuid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_retranscribe\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df1.copy()\n",
    "df.rename(columns={'orig_sentence':'x_orig', 'sentence':'y_orig'}, inplace=True)\n",
    "df.drop(['uuid','is_retranscribe'], axis=1, inplace=True)\n",
    "df = df.loc[:100]\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 28705, 32506, 28808, 28705, 33577, 28705, 51754, 30245, 28705, 33994, 28804]\n",
      "<s> שלום! מה שלומך היום?\n",
      "['<s>', '▁', 'שלום', '!', '▁', 'מה', '▁', 'שלומ', 'ך', '▁', 'היום', '?']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>אבל המרמבום הוא כותב שיש מובן נוסף לשמייו והוא...</td>\n",
       "      <td>אבל גם ברמבם הוא כותב שיש מובן נוסף להשמיע והו...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>נגיד קהילת ישראל קהילת צרפת ספרד וכו</td>\n",
       "      <td>נגיד קהילת ישראל קהילת צרפת ספרד וכו</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>בעיקרון זה פשוט אין סיבה שאתה תתחבר למיטאפ שלא...</td>\n",
       "      <td>בעיקרון זה פשוט אין סיבה שאתה תתחבר למיטאפ שלא...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>למה לא מה מה מה כואב לנו לקוות ולמקווי חיפה נקווה</td>\n",
       "      <td>בוא נקווה למה לא מה מה מה כואב לנו לקוות ולמכב...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>מי אחד לאחד מי אחד מכל אחד לכל אחד</td>\n",
       "      <td>מי אחד לאחד מי אחד מכל אחד לכל אחד</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>בתיבת הטקסט שנמצאת בימין המסך</td>\n",
       "      <td>בתיבת הטקסט שנמצאת בימין המסך</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>שאין לך יכולת לתפוס את הקנה מידע שלהם חוקי פאר...</td>\n",
       "      <td>שאין לך יכולת לתפוס את הקנה מידה שלהם חוקי פאר...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ובמה שאני אומר היום היום גם</td>\n",
       "      <td>ובמה שאני אומר היום היום גם</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>עכשיו הוא אומר לי זה בסדר הוא אומר ראיתי את המ...</td>\n",
       "      <td>אהההה עכשיו הוא אומר לי אההה זה זה בסדר הוא או...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>תגיד לדי שרשם דברים את רוצה</td>\n",
       "      <td>חגית ראיתי שרשמת דברים את רוצה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ומטרות שונות בתחום ההוראה גם תקציב</td>\n",
       "      <td>אההה ומטרות שונות בתחום ההוראה גם תקציב אהה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>זאת הייתה אני חושב קודם כל הפעם הראשונה שלי שר...</td>\n",
       "      <td>זאת הייתה אני חושב קודם כל הפעם הראשונה שלי שר...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>זה לא רלוונטי שיקדמו אותך</td>\n",
       "      <td>זה לא זה לא רלוונטי אליה שיקדמו אותך</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>או שנאמרו שהדברים שלי ממש היו קשים לבחינתי לא ...</td>\n",
       "      <td>או שנאמרו שהדברים שלי ממש היו קשים מבחינתינו מ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>אותי במקום של הדיגיטציה במקום שלה</td>\n",
       "      <td>הודי במקום של הדיגיטציה במקום של ה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>של תום פרידמן זה הספר הראשון שהוא כתב</td>\n",
       "      <td>של תום פרידמן זה הספר הראשון שהוא כתב</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>באחד הדברים שאנחנו עושים במרכז הישראלי להתמוקד...</td>\n",
       "      <td>באחד הדברים שאנחנו עושים במרכז הישראלי להתמכרו...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>דברים שמתחברים אל הלב כי</td>\n",
       "      <td>דברים שמתחברים אל הלב כי</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>קהילת הטראנס נפגשת הרבה עם רופאים ורופאות בין ...</td>\n",
       "      <td>קהילת הטראנס נפגשת הרבה עם רופאים ורופאות בין ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>באמת מטורף אף פעם לא היו כלים</td>\n",
       "      <td>באמת מטורף אף פעם לא היו כלים</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>אול דה פאריש מרובה פאריש מכיוון שבעברית פשוטה</td>\n",
       "      <td>אול דפריש מרובה פריש מכיוון שבעברית פשוטה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>לגיל לעוצמו זאת אומרת ילד שקשה לו להיפרד מאימא...</td>\n",
       "      <td>לגיל לעוצמו זאת אומרת ילד שקשה לו להיפרד מאימא...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ואז אני בדבר בשפה שלה היא באותה מידה יכולה להג...</td>\n",
       "      <td>ואז אני בדבר בשפה שלה היא באותה מידה יכולה להג...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>לא לא מגניב מה שאני מנסה להגיד אבל זה ש</td>\n",
       "      <td>לא לא מגניב מה שאני מנסה להגיד אבל זה ש</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>טיפולים וכימותים פרבולים ועוד אף שהוא פשוט</td>\n",
       "      <td>טיפולים וכימותים פרבולים ועוד אף שהוא פשוט</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>זה סוגיה של תנאים סניטריים אבל אני עכשיו רוצה ...</td>\n",
       "      <td>זה סוגיה של תנאים סניטריים אבל אני עכשיו רוצה ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>הוא עדיין צעיר שיש לו רק בין 25</td>\n",
       "      <td>והוא עדיין צעיר אני חושב שהוא רק בן 25 או משהו...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>אוקיי וזה גורם לך זה משהו פנימי אם זה בזמן משח...</td>\n",
       "      <td>אוקיי וזה גורם לך זה משהו פנימי אם זה בזמן משח...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>של למשל צורת הקשר או ה</td>\n",
       "      <td>של למשל צורת הקשר או ה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>באמת להיות גדול וגיבור ולעצב את העולם</td>\n",
       "      <td>באמת להיות גדול וגיבור ולעצב את העולם</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>זה רמת גן זה כאילו משהו בין ראש העין לסאוף קרו...</td>\n",
       "      <td>זה רמת גן זה כאילו משהו בין ראש העין לסאות קרו...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>הוקחינו חובה עד גיל 12 אחר כך זה עד גיל 3 וזה ...</td>\n",
       "      <td>חוק חינוך חובה עד גיל 12 אחר כך זה עד גיל 3 וז...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>עקותיות בעיות משנות מציאות</td>\n",
       "      <td>אקוטיות בעיות משנות מציאות</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>העובדים של מיליו שהם עובדים מאוד מאוד קשה שהחב...</td>\n",
       "      <td>העובדים של מיליו שהם עובדים מאוד מאוד קשה שהחב...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>חברה הקונגלומרטים אתה יודע</td>\n",
       "      <td>חברה הקונגלומרטים אתה יודע</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>בעייתי מאוד מבחינה טכנית כי יש שם עומקים של 30...</td>\n",
       "      <td>בעייתי מאוד מבחינה טכנית כי יש שם עומקים של 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>באותו יום הוא גם בחינם לדעתי אחד מהם אחד מהם ב...</td>\n",
       "      <td>באותו יום הוא גם בחינם לדעתי אחד מהם אחד מהם ב...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>זה תקווה כאילו נראה לי שגם הייתה מבוססת באיזשה...</td>\n",
       "      <td>זה תקווה כאילו נראה לי שגם הייתה מבוססת באיזשה...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>מה שהם כתבו בוודאי היה</td>\n",
       "      <td>מה שהם כתבו בוודאי היה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ובדוקטורט אני רוצה להזכיר מה היה במפגשים הקודמ...</td>\n",
       "      <td>ובדוקטורט אני רוצה להזכיר מה היה במפגשים הקודמ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>מה הולך לשרת אתכם למשך איזה זמן</td>\n",
       "      <td>מה הולך לשרת אתכם למשך איזה זמן</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>דוגמא אחת מה זה קונספציה מסוכנת</td>\n",
       "      <td>דוגמא אחת מה זה קונספציה מסוכנת</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>בעצם השלוש מאות וחמישה עשר האלה בנויים</td>\n",
       "      <td>בעצם השלוש מאות וחמישה עשר האלה בנויים</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>גם אשמנת יתר גם אנטיביוטיקה כזאת אז יכול להתלה...</td>\n",
       "      <td>גם השמנת יתר גם אנטיביוטיקה כזאת אז יכולות להי...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>דבר שאנשים מאוד מתעניינים בו</td>\n",
       "      <td>דבר שאנשים מאוד מתעניינים בו</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>אסכים איתך לגמרי ישר לסטרימינג אבל מעולה</td>\n",
       "      <td>אסכים איתך לגמרי ישר לסטרימינג אבל מעולה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>לפחות 3 4 שנים אם הוא כבר אכל את הלב בתקופה הזאת</td>\n",
       "      <td>לפחות 3 4 שנים אם הוא כבר אכל את הלב בתקופה הזאת</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>אתה אמרת ודיאקת וגם ראיתי אתמול מה כתבת בצוויצר</td>\n",
       "      <td>אתה אמרת ודייקת וגם ראיתי אתמול מה כתבת בטיווטר</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>כל עוד הוא משחק כמו שהוא משחק שיעלה עם הליכון ...</td>\n",
       "      <td>כל עוד הוא משחק כמו שהוא משחק שיעלה עם הליכון ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>אז הוא שבר את הפרדיגמה והיא התחלתה ב</td>\n",
       "      <td>אז הוא שבר את הפרדיגמה והיא התחלתה ב</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>הרבה יותר מרגש והרבה יותר משמעותי ממה שחשבתי ש...</td>\n",
       "      <td>הרבה יותר מרגש והרבה יותר משמעותי ממה שחשבתי ש...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>בניגוד למוות בסוף חיים</td>\n",
       "      <td>בניגוד למוות בסוף חיים</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>בסדר יש עוד איזה נושאים שהיית רוצה לחדד שמסביר...</td>\n",
       "      <td>בסדר יש עוד איזה נושאים שהיית רוצה לחדד שמסרים...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>זה מצב הארים שלנו אם בעצם אנחנו חיים בארים שכי...</td>\n",
       "      <td>זה מצב הערים שלנו אם בעצם אנחנו חיים בערים שכי...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>אותו דבר ויהיה ישראל הם יכולים ליהנות פה משווי...</td>\n",
       "      <td>אותו דבר ערביי ישראל הם יכולים ליהנות פה משווי...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>אני מקווה במפגש הזה לחזור לכם הרבה מאוד זמן של...</td>\n",
       "      <td>אני מקווה במפגש הזה לחסוך לכם הרבה מאוד זמן של...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>מאלה שהוא היו בעונה הראשונה המלצה האישית שלי היא</td>\n",
       "      <td>מאלה שהוא היו בעונה הראשונה המלצה האישית שלי היא</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>אבל בואו נתחיל באמת הבעיה ואני חושבת שוורד חוו...</td>\n",
       "      <td>אבל בואו נתחיל באמת הבעיה ואני חושבת שורד חוות...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>אני לא כך רואה איזושהי אפליה מאוד חזקה ובסך הכ...</td>\n",
       "      <td>אני לא כך רואה איזושהי אפליה מאוד חזקה ובסך הכ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ניהלו את המאזנים שלהם בצורה הרבה יותר טובה ומג...</td>\n",
       "      <td>ניהלו את המאזנים שלהם בצורה הרבה יותר טובה ומג...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ירום הודו והבחר בך לסרט שלו או לסדרה שלו</td>\n",
       "      <td>ירום הודו ויבחר בך לסרט שלו או לסדרה שלו</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>באותה הטיסה באותה הטיסה זה מאוד מפחיד זה מטור ...</td>\n",
       "      <td>באותה הטיסה באותה הטיסה זה מאוד מפחיד זה מטור ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>העין שלנו מלאה בנוזל ומאוד מאוד קשה לנתח אותה ...</td>\n",
       "      <td>העין שלנו מלאה בנוזל ומאוד מאוד קשה לנתח אותה ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>שכן נמצא תחת טיפול תרופתי או שאולי צריך להיות ...</td>\n",
       "      <td>שכן נמצא תחת טיפול תרופתיכן או שאולי צריך להיו...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>אז אני רוצה להודות לך מאוד מאוד מאוד על שיחה ס...</td>\n",
       "      <td>אז אני רוצה להודות לך מאוד מאוד מאוד על שיחה ס...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>אין לך פרפורמנס שאתה סטארט אפ אין לך כל מיני ל...</td>\n",
       "      <td>אין לך פרפורמנס שאתה סטארט אפ אין לך כל מיני ל...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>לא חושבת שאנחנו עדיפים על מישהו אחר</td>\n",
       "      <td>לא חושבת שאנחנו עדיפים על מישהו אחר</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>זה ליצור סרטונים אינטראקטיביים שזה שילוב של סרטים</td>\n",
       "      <td>זה ליצור סרטונים אינטראקטיביים שזה שילוב של סרטים</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>שאנחנו נמצאים בהתחלה</td>\n",
       "      <td>שאנחנו נמצאים בהתחלה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ויודעים כמה היו המזונות בערך בסדר</td>\n",
       "      <td>ויודעים כמה יהיו המזונות בערך בסדר</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>של השבק ואז פתאום אמרתי לעצמי יש כאן לקח יותר רחב</td>\n",
       "      <td>של השבב ואז פתאום אמרתי לעצמי יש כאן לקח יותר רחב</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>לא היית צריך לעבוד בעבודה מאייפת והיית יכול לה...</td>\n",
       "      <td>לא היית צריך לעבוד בעבודה מעייפת והיית יכול לה...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>מנוחה ומתעסק פחות עם איך הגקט נראה ואיך העיניי...</td>\n",
       "      <td>במנוחה ומתעסק פחות עם איך הגקט נראה ואיך העיני...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>והאינטרס המקומי אבל די ביטוי באה</td>\n",
       "      <td>והאינטרס המקומי יבוא לידי ביטוי ב</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>הבנה של פעילות חישובית בעולם של קליפת המוח קורטקס</td>\n",
       "      <td>הבנה של פעילות חישובית בתחום בעולם של קליפת המ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>אז בעצם האתגר הפיזיקלי זה אותו בידוד</td>\n",
       "      <td>אז בעצם האתגר הפיזיקלי זה אותו בידוד</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>הוא שיר את מקאי בליגה כשזה היה איזה עונה אחת א...</td>\n",
       "      <td>הוא השאיר את מקאיי בליגה לאיזה עונה אחת אין בס...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>המחנה השמאל היה מתעורר קצת יותר מוקדם לסיפור ה...</td>\n",
       "      <td>המחנה השמאל היה מתעורר קצת יותר מוקדם לסיפור ה...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>בוקר יום ראשון שמונה עד עשר</td>\n",
       "      <td>בוקר יום ראשון שמונה עד עשר</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>שהוא גם האזין קבוע שלנו וגם במייקל נועה בעצמו</td>\n",
       "      <td>שהוא גם מאזין קבוע שלנו וגם במאי קולנוע בעצמו</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>בשביל זה צריך להיות קצת היסטוריון ולהכיר ולא ל...</td>\n",
       "      <td>בשביל זה צריך להיות קצת היסטוריון ולהכיר ולא ל...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>ואת הדבר הזה צריך לבצע על איזשהו</td>\n",
       "      <td>ואת הדבר הזה צריך לבצע על איזשהו</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>אתה נראה לחשוד אתה נראה לא טוב עוף מפה</td>\n",
       "      <td>אתה נראה לי חשוד אתה נראה לא טוב עוף מפה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ובגרמניה מאוד מאוד קר בחורף והחורף הם הולכים ל...</td>\n",
       "      <td>ובגרמניה מאוד מאוד קר בחורף והחורף הם הולכים ל...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>בלי שום קשר לקורונה</td>\n",
       "      <td>בלי שום קשר לקורונה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>שנמכרו ממש לא מזמן לחברת וויקס חברת פניית האתר...</td>\n",
       "      <td>שנמכרו ממש לא מזמן לחברת וויקס חברת בניית האתר...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>אבל מצד שני אני גם לא נותן</td>\n",
       "      <td>אבל מצד שני אני גם לא נותן</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>או לחילופין אמר זה התעודת ביטוח של לבנון כן מה...</td>\n",
       "      <td>או לחילופין אמר זה התעודת ביטוח של לבנון כן מה...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>נכון אבל ההבדל בין החוזה שלהם לחוזה שלי זה שהם...</td>\n",
       "      <td>נכון אבל ההבדל בין החוזה שלהם לחוזה שלי זה שהם...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>אני מת עליו אני מת על הקבוצה הזאתי והיה לי כל ...</td>\n",
       "      <td>אני מת עליו אני מת על הקבוצה הזאתי והיה לי כל ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>אתה כבר אתה אפילו לא חייב מתכונים זה עוזר כי ז...</td>\n",
       "      <td>אתה כבר אתה אפילו לא חייב מתכונים זה עוזר כי ז...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>מי שממש לא עוד לא עוזר אקסלרציה יש היום הרבה ב...</td>\n",
       "      <td>מי שממש לא עוד לא זה אקסלרציה יש היום הרבה באר...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>כן אז אני רציתי סתם לדבר על מה קורה בדיון ששופ...</td>\n",
       "      <td>כן אז אז אני רציתי סתם לדבר על מה קורה בדיון ש...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>רבים מאלף ומתיים המגורשים לטבריה</td>\n",
       "      <td>רבים מאלף ומאתיים המגורשים לטבריה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>הוא מסתובב ככה זה קטע מלא גרביים לבנות ספורט מ...</td>\n",
       "      <td>הוא מסתובב ככה זה קטע מלא גרביים לבנות ספורט מ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>שותפים הגי פיז שגייסו את הכסף מהאל פיז</td>\n",
       "      <td>שותפים הגי פיז שגייסו את הכסף מהאל פיז</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>אני היחיד שחושב על פייט קלאב עכשיו תגיד לי אני...</td>\n",
       "      <td>אני היחיד שחושב על פייט קלאב עכשיו תגיד לי אני...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>למויאל לזה לעבור את כל מדבר טורקאנה זה טיול בפ...</td>\n",
       "      <td>למויאל לזה לעבור את כל מדבר טורקאנה זה טיול בפ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>יותר להשפיע על העבודה של הממשלה</td>\n",
       "      <td>יותר להשפיע על העבודה של הממשלה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>אנחנו היום נמצאים במאה ה 21 ואיפה הדבר הזה של ה</td>\n",
       "      <td>אנחנו היום נמצאים במאה ה 21 ואיפה הדבר הזה של ה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>שאני לא אחזור עליה עם הילדים שלי ושיתפתי איתם ...</td>\n",
       "      <td>שאני לא אחזור עליה עם הילדים שלי ושיתפתי איתם ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     x  \\\n",
       "0    אבל המרמבום הוא כותב שיש מובן נוסף לשמייו והוא...   \n",
       "1                 נגיד קהילת ישראל קהילת צרפת ספרד וכו   \n",
       "2    בעיקרון זה פשוט אין סיבה שאתה תתחבר למיטאפ שלא...   \n",
       "3    למה לא מה מה מה כואב לנו לקוות ולמקווי חיפה נקווה   \n",
       "4                   מי אחד לאחד מי אחד מכל אחד לכל אחד   \n",
       "5                        בתיבת הטקסט שנמצאת בימין המסך   \n",
       "6    שאין לך יכולת לתפוס את הקנה מידע שלהם חוקי פאר...   \n",
       "7                          ובמה שאני אומר היום היום גם   \n",
       "8    עכשיו הוא אומר לי זה בסדר הוא אומר ראיתי את המ...   \n",
       "9                          תגיד לדי שרשם דברים את רוצה   \n",
       "10                  ומטרות שונות בתחום ההוראה גם תקציב   \n",
       "11   זאת הייתה אני חושב קודם כל הפעם הראשונה שלי שר...   \n",
       "12                           זה לא רלוונטי שיקדמו אותך   \n",
       "13   או שנאמרו שהדברים שלי ממש היו קשים לבחינתי לא ...   \n",
       "14                   אותי במקום של הדיגיטציה במקום שלה   \n",
       "15               של תום פרידמן זה הספר הראשון שהוא כתב   \n",
       "16   באחד הדברים שאנחנו עושים במרכז הישראלי להתמוקד...   \n",
       "17                            דברים שמתחברים אל הלב כי   \n",
       "18   קהילת הטראנס נפגשת הרבה עם רופאים ורופאות בין ...   \n",
       "19                       באמת מטורף אף פעם לא היו כלים   \n",
       "20       אול דה פאריש מרובה פאריש מכיוון שבעברית פשוטה   \n",
       "21   לגיל לעוצמו זאת אומרת ילד שקשה לו להיפרד מאימא...   \n",
       "22   ואז אני בדבר בשפה שלה היא באותה מידה יכולה להג...   \n",
       "23             לא לא מגניב מה שאני מנסה להגיד אבל זה ש   \n",
       "24          טיפולים וכימותים פרבולים ועוד אף שהוא פשוט   \n",
       "25   זה סוגיה של תנאים סניטריים אבל אני עכשיו רוצה ...   \n",
       "26                     הוא עדיין צעיר שיש לו רק בין 25   \n",
       "27   אוקיי וזה גורם לך זה משהו פנימי אם זה בזמן משח...   \n",
       "28                              של למשל צורת הקשר או ה   \n",
       "29               באמת להיות גדול וגיבור ולעצב את העולם   \n",
       "30   זה רמת גן זה כאילו משהו בין ראש העין לסאוף קרו...   \n",
       "31   הוקחינו חובה עד גיל 12 אחר כך זה עד גיל 3 וזה ...   \n",
       "32                          עקותיות בעיות משנות מציאות   \n",
       "33   העובדים של מיליו שהם עובדים מאוד מאוד קשה שהחב...   \n",
       "34                          חברה הקונגלומרטים אתה יודע   \n",
       "35   בעייתי מאוד מבחינה טכנית כי יש שם עומקים של 30...   \n",
       "36   באותו יום הוא גם בחינם לדעתי אחד מהם אחד מהם ב...   \n",
       "37   זה תקווה כאילו נראה לי שגם הייתה מבוססת באיזשה...   \n",
       "38                              מה שהם כתבו בוודאי היה   \n",
       "39   ובדוקטורט אני רוצה להזכיר מה היה במפגשים הקודמ...   \n",
       "40                     מה הולך לשרת אתכם למשך איזה זמן   \n",
       "41                     דוגמא אחת מה זה קונספציה מסוכנת   \n",
       "42              בעצם השלוש מאות וחמישה עשר האלה בנויים   \n",
       "43   גם אשמנת יתר גם אנטיביוטיקה כזאת אז יכול להתלה...   \n",
       "44                        דבר שאנשים מאוד מתעניינים בו   \n",
       "45            אסכים איתך לגמרי ישר לסטרימינג אבל מעולה   \n",
       "46    לפחות 3 4 שנים אם הוא כבר אכל את הלב בתקופה הזאת   \n",
       "47     אתה אמרת ודיאקת וגם ראיתי אתמול מה כתבת בצוויצר   \n",
       "48   כל עוד הוא משחק כמו שהוא משחק שיעלה עם הליכון ...   \n",
       "49                אז הוא שבר את הפרדיגמה והיא התחלתה ב   \n",
       "50   הרבה יותר מרגש והרבה יותר משמעותי ממה שחשבתי ש...   \n",
       "51                              בניגוד למוות בסוף חיים   \n",
       "52   בסדר יש עוד איזה נושאים שהיית רוצה לחדד שמסביר...   \n",
       "53   זה מצב הארים שלנו אם בעצם אנחנו חיים בארים שכי...   \n",
       "54   אותו דבר ויהיה ישראל הם יכולים ליהנות פה משווי...   \n",
       "55   אני מקווה במפגש הזה לחזור לכם הרבה מאוד זמן של...   \n",
       "56    מאלה שהוא היו בעונה הראשונה המלצה האישית שלי היא   \n",
       "57   אבל בואו נתחיל באמת הבעיה ואני חושבת שוורד חוו...   \n",
       "58   אני לא כך רואה איזושהי אפליה מאוד חזקה ובסך הכ...   \n",
       "59   ניהלו את המאזנים שלהם בצורה הרבה יותר טובה ומג...   \n",
       "60            ירום הודו והבחר בך לסרט שלו או לסדרה שלו   \n",
       "61   באותה הטיסה באותה הטיסה זה מאוד מפחיד זה מטור ...   \n",
       "62   העין שלנו מלאה בנוזל ומאוד מאוד קשה לנתח אותה ...   \n",
       "63   שכן נמצא תחת טיפול תרופתי או שאולי צריך להיות ...   \n",
       "64   אז אני רוצה להודות לך מאוד מאוד מאוד על שיחה ס...   \n",
       "65   אין לך פרפורמנס שאתה סטארט אפ אין לך כל מיני ל...   \n",
       "66                 לא חושבת שאנחנו עדיפים על מישהו אחר   \n",
       "67   זה ליצור סרטונים אינטראקטיביים שזה שילוב של סרטים   \n",
       "68                                שאנחנו נמצאים בהתחלה   \n",
       "69                   ויודעים כמה היו המזונות בערך בסדר   \n",
       "70   של השבק ואז פתאום אמרתי לעצמי יש כאן לקח יותר רחב   \n",
       "71   לא היית צריך לעבוד בעבודה מאייפת והיית יכול לה...   \n",
       "72   מנוחה ומתעסק פחות עם איך הגקט נראה ואיך העיניי...   \n",
       "73                    והאינטרס המקומי אבל די ביטוי באה   \n",
       "74   הבנה של פעילות חישובית בעולם של קליפת המוח קורטקס   \n",
       "75                אז בעצם האתגר הפיזיקלי זה אותו בידוד   \n",
       "76   הוא שיר את מקאי בליגה כשזה היה איזה עונה אחת א...   \n",
       "77   המחנה השמאל היה מתעורר קצת יותר מוקדם לסיפור ה...   \n",
       "78                         בוקר יום ראשון שמונה עד עשר   \n",
       "79       שהוא גם האזין קבוע שלנו וגם במייקל נועה בעצמו   \n",
       "80   בשביל זה צריך להיות קצת היסטוריון ולהכיר ולא ל...   \n",
       "81                    ואת הדבר הזה צריך לבצע על איזשהו   \n",
       "82              אתה נראה לחשוד אתה נראה לא טוב עוף מפה   \n",
       "83   ובגרמניה מאוד מאוד קר בחורף והחורף הם הולכים ל...   \n",
       "84                                 בלי שום קשר לקורונה   \n",
       "85   שנמכרו ממש לא מזמן לחברת וויקס חברת פניית האתר...   \n",
       "86                          אבל מצד שני אני גם לא נותן   \n",
       "87   או לחילופין אמר זה התעודת ביטוח של לבנון כן מה...   \n",
       "88   נכון אבל ההבדל בין החוזה שלהם לחוזה שלי זה שהם...   \n",
       "89   אני מת עליו אני מת על הקבוצה הזאתי והיה לי כל ...   \n",
       "90   אתה כבר אתה אפילו לא חייב מתכונים זה עוזר כי ז...   \n",
       "91   מי שממש לא עוד לא עוזר אקסלרציה יש היום הרבה ב...   \n",
       "92   כן אז אני רציתי סתם לדבר על מה קורה בדיון ששופ...   \n",
       "93                    רבים מאלף ומתיים המגורשים לטבריה   \n",
       "94   הוא מסתובב ככה זה קטע מלא גרביים לבנות ספורט מ...   \n",
       "95              שותפים הגי פיז שגייסו את הכסף מהאל פיז   \n",
       "96   אני היחיד שחושב על פייט קלאב עכשיו תגיד לי אני...   \n",
       "97   למויאל לזה לעבור את כל מדבר טורקאנה זה טיול בפ...   \n",
       "98                     יותר להשפיע על העבודה של הממשלה   \n",
       "99     אנחנו היום נמצאים במאה ה 21 ואיפה הדבר הזה של ה   \n",
       "100  שאני לא אחזור עליה עם הילדים שלי ושיתפתי איתם ...   \n",
       "\n",
       "                                                     y  \n",
       "0    אבל גם ברמבם הוא כותב שיש מובן נוסף להשמיע והו...  \n",
       "1                 נגיד קהילת ישראל קהילת צרפת ספרד וכו  \n",
       "2    בעיקרון זה פשוט אין סיבה שאתה תתחבר למיטאפ שלא...  \n",
       "3    בוא נקווה למה לא מה מה מה כואב לנו לקוות ולמכב...  \n",
       "4                   מי אחד לאחד מי אחד מכל אחד לכל אחד  \n",
       "5                        בתיבת הטקסט שנמצאת בימין המסך  \n",
       "6    שאין לך יכולת לתפוס את הקנה מידה שלהם חוקי פאר...  \n",
       "7                          ובמה שאני אומר היום היום גם  \n",
       "8    אהההה עכשיו הוא אומר לי אההה זה זה בסדר הוא או...  \n",
       "9                       חגית ראיתי שרשמת דברים את רוצה  \n",
       "10         אההה ומטרות שונות בתחום ההוראה גם תקציב אהה  \n",
       "11   זאת הייתה אני חושב קודם כל הפעם הראשונה שלי שר...  \n",
       "12                זה לא זה לא רלוונטי אליה שיקדמו אותך  \n",
       "13   או שנאמרו שהדברים שלי ממש היו קשים מבחינתינו מ...  \n",
       "14                  הודי במקום של הדיגיטציה במקום של ה  \n",
       "15               של תום פרידמן זה הספר הראשון שהוא כתב  \n",
       "16   באחד הדברים שאנחנו עושים במרכז הישראלי להתמכרו...  \n",
       "17                            דברים שמתחברים אל הלב כי  \n",
       "18   קהילת הטראנס נפגשת הרבה עם רופאים ורופאות בין ...  \n",
       "19                       באמת מטורף אף פעם לא היו כלים  \n",
       "20           אול דפריש מרובה פריש מכיוון שבעברית פשוטה  \n",
       "21   לגיל לעוצמו זאת אומרת ילד שקשה לו להיפרד מאימא...  \n",
       "22   ואז אני בדבר בשפה שלה היא באותה מידה יכולה להג...  \n",
       "23             לא לא מגניב מה שאני מנסה להגיד אבל זה ש  \n",
       "24          טיפולים וכימותים פרבולים ועוד אף שהוא פשוט  \n",
       "25   זה סוגיה של תנאים סניטריים אבל אני עכשיו רוצה ...  \n",
       "26   והוא עדיין צעיר אני חושב שהוא רק בן 25 או משהו...  \n",
       "27   אוקיי וזה גורם לך זה משהו פנימי אם זה בזמן משח...  \n",
       "28                              של למשל צורת הקשר או ה  \n",
       "29               באמת להיות גדול וגיבור ולעצב את העולם  \n",
       "30   זה רמת גן זה כאילו משהו בין ראש העין לסאות קרו...  \n",
       "31   חוק חינוך חובה עד גיל 12 אחר כך זה עד גיל 3 וז...  \n",
       "32                          אקוטיות בעיות משנות מציאות  \n",
       "33   העובדים של מיליו שהם עובדים מאוד מאוד קשה שהחב...  \n",
       "34                          חברה הקונגלומרטים אתה יודע  \n",
       "35   בעייתי מאוד מבחינה טכנית כי יש שם עומקים של 30...  \n",
       "36   באותו יום הוא גם בחינם לדעתי אחד מהם אחד מהם ב...  \n",
       "37   זה תקווה כאילו נראה לי שגם הייתה מבוססת באיזשה...  \n",
       "38                              מה שהם כתבו בוודאי היה  \n",
       "39   ובדוקטורט אני רוצה להזכיר מה היה במפגשים הקודמ...  \n",
       "40                     מה הולך לשרת אתכם למשך איזה זמן  \n",
       "41                     דוגמא אחת מה זה קונספציה מסוכנת  \n",
       "42              בעצם השלוש מאות וחמישה עשר האלה בנויים  \n",
       "43   גם השמנת יתר גם אנטיביוטיקה כזאת אז יכולות להי...  \n",
       "44                        דבר שאנשים מאוד מתעניינים בו  \n",
       "45            אסכים איתך לגמרי ישר לסטרימינג אבל מעולה  \n",
       "46    לפחות 3 4 שנים אם הוא כבר אכל את הלב בתקופה הזאת  \n",
       "47     אתה אמרת ודייקת וגם ראיתי אתמול מה כתבת בטיווטר  \n",
       "48   כל עוד הוא משחק כמו שהוא משחק שיעלה עם הליכון ...  \n",
       "49                אז הוא שבר את הפרדיגמה והיא התחלתה ב  \n",
       "50   הרבה יותר מרגש והרבה יותר משמעותי ממה שחשבתי ש...  \n",
       "51                              בניגוד למוות בסוף חיים  \n",
       "52   בסדר יש עוד איזה נושאים שהיית רוצה לחדד שמסרים...  \n",
       "53   זה מצב הערים שלנו אם בעצם אנחנו חיים בערים שכי...  \n",
       "54   אותו דבר ערביי ישראל הם יכולים ליהנות פה משווי...  \n",
       "55   אני מקווה במפגש הזה לחסוך לכם הרבה מאוד זמן של...  \n",
       "56    מאלה שהוא היו בעונה הראשונה המלצה האישית שלי היא  \n",
       "57   אבל בואו נתחיל באמת הבעיה ואני חושבת שורד חוות...  \n",
       "58   אני לא כך רואה איזושהי אפליה מאוד חזקה ובסך הכ...  \n",
       "59   ניהלו את המאזנים שלהם בצורה הרבה יותר טובה ומג...  \n",
       "60            ירום הודו ויבחר בך לסרט שלו או לסדרה שלו  \n",
       "61   באותה הטיסה באותה הטיסה זה מאוד מפחיד זה מטור ...  \n",
       "62   העין שלנו מלאה בנוזל ומאוד מאוד קשה לנתח אותה ...  \n",
       "63   שכן נמצא תחת טיפול תרופתיכן או שאולי צריך להיו...  \n",
       "64   אז אני רוצה להודות לך מאוד מאוד מאוד על שיחה ס...  \n",
       "65   אין לך פרפורמנס שאתה סטארט אפ אין לך כל מיני ל...  \n",
       "66                 לא חושבת שאנחנו עדיפים על מישהו אחר  \n",
       "67   זה ליצור סרטונים אינטראקטיביים שזה שילוב של סרטים  \n",
       "68                                שאנחנו נמצאים בהתחלה  \n",
       "69                  ויודעים כמה יהיו המזונות בערך בסדר  \n",
       "70   של השבב ואז פתאום אמרתי לעצמי יש כאן לקח יותר רחב  \n",
       "71   לא היית צריך לעבוד בעבודה מעייפת והיית יכול לה...  \n",
       "72   במנוחה ומתעסק פחות עם איך הגקט נראה ואיך העיני...  \n",
       "73                   והאינטרס המקומי יבוא לידי ביטוי ב  \n",
       "74   הבנה של פעילות חישובית בתחום בעולם של קליפת המ...  \n",
       "75                אז בעצם האתגר הפיזיקלי זה אותו בידוד  \n",
       "76   הוא השאיר את מקאיי בליגה לאיזה עונה אחת אין בס...  \n",
       "77   המחנה השמאל היה מתעורר קצת יותר מוקדם לסיפור ה...  \n",
       "78                         בוקר יום ראשון שמונה עד עשר  \n",
       "79       שהוא גם מאזין קבוע שלנו וגם במאי קולנוע בעצמו  \n",
       "80   בשביל זה צריך להיות קצת היסטוריון ולהכיר ולא ל...  \n",
       "81                    ואת הדבר הזה צריך לבצע על איזשהו  \n",
       "82            אתה נראה לי חשוד אתה נראה לא טוב עוף מפה  \n",
       "83   ובגרמניה מאוד מאוד קר בחורף והחורף הם הולכים ל...  \n",
       "84                                 בלי שום קשר לקורונה  \n",
       "85   שנמכרו ממש לא מזמן לחברת וויקס חברת בניית האתר...  \n",
       "86                          אבל מצד שני אני גם לא נותן  \n",
       "87   או לחילופין אמר זה התעודת ביטוח של לבנון כן מה...  \n",
       "88   נכון אבל ההבדל בין החוזה שלהם לחוזה שלי זה שהם...  \n",
       "89   אני מת עליו אני מת על הקבוצה הזאתי והיה לי כל ...  \n",
       "90   אתה כבר אתה אפילו לא חייב מתכונים זה עוזר כי ז...  \n",
       "91   מי שממש לא עוד לא זה אקסלרציה יש היום הרבה באר...  \n",
       "92   כן אז אז אני רציתי סתם לדבר על מה קורה בדיון ש...  \n",
       "93                   רבים מאלף ומאתיים המגורשים לטבריה  \n",
       "94   הוא מסתובב ככה זה קטע מלא גרביים לבנות ספורט מ...  \n",
       "95              שותפים הגי פיז שגייסו את הכסף מהאל פיז  \n",
       "96   אני היחיד שחושב על פייט קלאב עכשיו תגיד לי אני...  \n",
       "97   למויאל לזה לעבור את כל מדבר טורקאנה זה טיול בפ...  \n",
       "98                     יותר להשפיע על העבודה של הממשלה  \n",
       "99     אנחנו היום נמצאים במאה ה 21 ואיפה הדבר הזה של ה  \n",
       "100  שאני לא אחזור עליה עם הילדים שלי ושיתפתי איתם ...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['x'] = remove_special_chars(df['x_orig'].copy())\n",
    "df['y'] = remove_special_chars(df['y_orig'].copy())\n",
    "\n",
    "# count words in df\n",
    "df['x_count'] = df['x'].apply(lambda x: len(str(x).split()))\n",
    "df['y_count'] = df['y'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "df[['x','y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12', '14', '18', '2', '2000', '2006', '2019', '21', '25', '3', '3000', '4', 'אבדולאי', 'אבל', 'או', 'אוהב', 'אוהבים', 'אול', 'אומר', 'אומרת', 'אוקיי', 'אותה', 'אותו', 'אותי', 'אותך', 'אז', 'אזרחי', 'אחד', 'אחזור', 'אחייד', 'אחר', 'אחרי', 'אחרים', 'אחת', 'איזה', 'איזושהי', 'איזשהו', 'איך', 'אין', 'אינטראקטיביים', 'איתו', 'איתך', 'איתם', 'אכל', 'אל', 'אליך', 'אליפות', 'אלפות', 'אם', 'אמר', 'אמרו', 'אמרת', 'אמרתי', 'אנחנו', 'אנטיביוטיקה', 'אני', 'אנכרוניסט', 'אנשים', 'אסכים', 'אף', 'אפ', 'אפילו', 'אפליה', 'אקסלרציה', 'ארים', 'אשמנת', 'את', 'אתה', 'אתכם', 'אתם', 'אתמול', 'ב', 'בא', 'באה', 'באופן', 'באותה', 'באותו', 'באחד', 'באיזשהו', 'באמת', 'בארים', 'בארץ', 'בגלל', 'בדבר', 'בדיון', 'בדקו', 'בהם', 'בהתחלה', 'בו', 'בוא', 'בואו', 'בוודאי', 'בוקר', 'בזמן', 'בחדר', 'בחור', 'בחורף', 'בחינם', 'בידוד', 'ביטוח', 'ביטוי', 'בימין', 'בין', 'בך', 'בכל', 'בכלל', 'בלי', 'בליגה', 'בלימודים', 'במאה', 'במייקל', 'במפגש', 'במפגשים', 'במקום', 'במרכז', 'בנוזל', 'בנויים', 'בניגוד', 'בניים', 'בס', 'בסדר', 'בסודיקה', 'בסוף', 'בסיפור', 'בעבודה', 'בעברות', 'בעולם', 'בעונה', 'בעיות', 'בעייתי', 'בעיקרון', 'בעצם', 'בעצמו', 'בערך', 'בפני', 'בצהל', 'בצוויצר', 'בצורה', 'בשביל', 'בשפה', 'בתחום', 'בתיבת', 'בתקופה', 'גדול', 'גוף', 'גורם', 'גזרה', 'גיל', 'גם', 'גמור', 'גן', 'גרביים', 'דבר', 'דברים', 'דה', 'דוגמא', 'די', 'דרך', 'ה', 'האזין', 'האישית', 'האלה', 'האם', 'האמיתית', 'הארים', 'האתגר', 'האתרים', 'הבנה', 'הבעיה', 'הגי', 'הגקט', 'הדבר', 'הדברים', 'הדיגיטציה', 'הדריכלים', 'ההבדל', 'ההוראה', 'הוא', 'הודו', 'הולך', 'הולכים', 'הוקחינו', 'הזאת', 'הזאתי', 'הזה', 'החוזה', 'הטיסה', 'הטקסט', 'הטראנס', 'היא', 'היה', 'היו', 'היום', 'היחיד', 'היית', 'הייתה', 'הילדים', 'היסטוריון', 'הישראלי', 'הכבוד', 'הכדור', 'הכול', 'הכסף', 'הלב', 'הליכון', 'הם', 'המאזנים', 'המאמן', 'המאמר', 'המגורשים', 'המוח', 'המזונות', 'המחנה', 'המטומטם', 'המלצה', 'הממשלה', 'המסך', 'המעליב', 'המקומי', 'המרכזי', 'המרמבום', 'המשחקים', 'המתכננים', 'הנה', 'הסגל', 'הספר', 'העבודה', 'העובדים', 'העולם', 'העין', 'העיניים', 'הפיזיקלי', 'הפעם', 'הפרדיגמה', 'הקבוצה', 'הקבלה', 'הקודמים', 'הקונגלומרטים', 'הקנה', 'הקשר', 'הראוי', 'הראשון', 'הראשונה', 'הרבה', 'הרי', 'הרפרנס', 'השבק', 'השילוב', 'השלוש', 'השמאל', 'השתלטתי', 'התאמה', 'התחלתה', 'התמודדות', 'התעודת', 'ואומרים', 'ואז', 'ואיך', 'ואיפה', 'ואני', 'ואת', 'ואתה', 'ובאמת', 'ובגרמניה', 'ובדוקטורט', 'ובין', 'ובמה', 'ובסך', 'וגיבור', 'וגם', 'ודיאקת', 'והאינטרס', 'והבחר', 'והוא', 'והחורף', 'והיא', 'והיה', 'והיחיד', 'והיית', 'והם', 'והסברתי', 'והרבה', 'וויקס', 'וזה', 'וחמישה', 'וטעו', 'ויהיה', 'ויודעים', 'וכו', 'וכולם', 'וכימותים', 'וכל', 'ולא', 'ולהיכנס', 'ולהכיר', 'ולמקווי', 'ולעצב', 'ומאוד', 'ומגוונת', 'ומטרות', 'ומפוזרת', 'ומתיים', 'ומתעסק', 'ונהנים', 'ועוד', 'וצריך', 'וצריכים', 'ורופאות', 'ושיתפתי', 'זאת', 'זה', 'זיין', 'זכויות', 'זמן', 'זרים', 'חברה', 'חברת', 'חדרים', 'חובה', 'חוותה', 'חוקי', 'חושב', 'חושבת', 'חזקה', 'חייב', 'חיים', 'חיפה', 'חישובית', 'חתולבה', 'טוב', 'טובה', 'טורקאנה', 'טיול', 'טיפול', 'טיפולי', 'טיפולים', 'טכנית', 'יהיה', 'יודע', 'יודעת', 'יום', 'יונתן', 'יוצרים', 'יורד', 'יותר', 'יכול', 'יכולה', 'יכולים', 'יכולת', 'ילד', 'ילדים', 'יפה', 'ירום', 'יש', 'ישר', 'ישראל', 'יתר', 'כאילו', 'כאלה', 'כאן', 'כאשר', 'כבוד', 'כבר', 'כואב', 'כותב', 'כזאת', 'כזה', 'כי', 'כיף', 'כך', 'ככה', 'כל', 'כלים', 'כמה', 'כמו', 'כן', 'כנראה', 'כשזה', 'כתב', 'כתבו', 'כתבת', 'ל', 'לא', 'לאחד', 'לבדיקה', 'לבחינתי', 'לבנון', 'לבנות', 'לבעיה', 'לבצע', 'לגיל', 'לגמרי', 'לדבר', 'לדי', 'לדעתי', 'להגיד', 'להודות', 'להזכיר', 'להיות', 'להיפרד', 'להישאר', 'להם', 'להניח', 'להעביר', 'להשפיע', 'להתלהלות', 'להתמוקד', 'להתרכז', 'לו', 'לוקחים', 'לזה', 'לחברת', 'לחדד', 'לחוות', 'לחוזה', 'לחזור', 'לחיות', 'לחילופין', 'לחנך', 'לחשוב', 'לחשוד', 'לטבריה', 'לי', 'ליגל', 'ליגת', 'ליד', 'ליהנות', 'לימוד', 'ליצור', 'לך', 'לכל', 'לכם', 'ללכת', 'למדתי', 'למה', 'למוות', 'למויאל', 'למיטאפ', 'למעלה', 'למשך', 'למשל', 'לנו', 'לנתח', 'לסאוף', 'לסדרה', 'לסטרימינג', 'לסיחה', 'לסיפור', 'לסרט', 'לעבוד', 'לעבור', 'לעוצמו', 'לעצמי', 'לפחות', 'לפייט', 'לפשטנות', 'לצרכים', 'לקוות', 'לקורונה', 'לקח', 'לשונית', 'לשמייו', 'לשרת', 'לתחומי', 'לתפוס', 'מאוד', 'מאות', 'מאייפת', 'מאימא', 'מאלה', 'מאלף', 'מבוססת', 'מבחינה', 'מבחינתך', 'מבטא', 'מבינה', 'מגדרית', 'מגניב', 'מדבר', 'מדויק', 'מה', 'מהאל', 'מהם', 'מהצד', 'מהר', 'מובן', 'מוח', 'מול', 'מוסרית', 'מוקדם', 'מורכבות', 'מזמן', 'מחבל', 'מטור', 'מטורף', 'מטר', 'מי', 'מידה', 'מידע', 'מיליו', 'מיני', 'מישהו', 'מכיוון', 'מכירה', 'מכל', 'מלא', 'מלאה', 'מלמדים', 'ממה', 'ממש', 'מנוחה', 'מניסיון', 'מנסה', 'מסוכנת', 'מסתובב', 'מעולה', 'מעניין', 'מעניינת', 'מפגינים', 'מפה', 'מפחיד', 'מפייט', 'מצב', 'מצד', 'מצדי', 'מציאות', 'מקאבי', 'מקאי', 'מקו', 'מקווה', 'מקום', 'מקשיב', 'מראה', 'מרגש', 'מרובה', 'מרחפים', 'משהו', 'משוויון', 'משחק', 'משם', 'משמעותי', 'משנות', 'משנת', 'מת', 'מתוחות', 'מתכונים', 'מתכנני', 'מתעורר', 'מתעניינים', 'מתעסק', 'מתרחבת', 'נאמנה', 'נגיד', 'נודה', 'נוסף', 'נועה', 'נושאים', 'נותן', 'ניהלו', 'נכון', 'נמצא', 'נמצאים', 'נעים', 'נפגשת', 'נפוסם', 'נקווה', 'נראה', 'נראות', 'נתחיל', 'סביב', 'סוגיה', 'סופר', 'סטארט', 'סיבה', 'סיבות', 'סייר', 'סיפרת', 'סניטריים', 'ספורט', 'ספרד', 'סצנה', 'סר', 'סרטונים', 'סרטים', 'סתם', 'עבודתם', 'עד', 'עדיין', 'עדיפים', 'עובדים', 'עוד', 'עוזר', 'עומקים', 'עונה', 'עוף', 'עושים', 'עכשיו', 'על', 'עליה', 'עליהם', 'עליו', 'עם', 'עצמו', 'עקותיות', 'עשר', 'פאריש', 'פארקינגסון', 'פה', 'פחות', 'פיז', 'פייט', 'פניית', 'פנימי', 'פעילות', 'פעם', 'פקודה', 'פקודת', 'פרבולים', 'פרידמן', 'פרפורמנס', 'פשוט', 'פשוטה', 'פתאום', 'צורת', 'צינור', 'צעיר', 'צריך', 'צריכים', 'צרפת', 'קבוע', 'קהילת', 'קודם', 'קונספציה', 'קורה', 'קורטקס', 'קטע', 'קלאב', 'קליפת', 'קנים', 'קפקפים', 'קצת', 'קר', 'קרוליינה', 'קשה', 'קשים', 'קשר', 'ראיתי', 'ראש', 'ראשון', 'רבים', 'רואה', 'רופאים', 'רוצה', 'רוצים', 'רחב', 'רלוונטי', 'רמת', 'רץ', 'רציתי', 'רק', 'רקע', 'ש', 'שאולי', 'שאין', 'שאנחנו', 'שאני', 'שאנשים', 'שאתה', 'שבאמת', 'שבעברית', 'שבעצם', 'שבר', 'שגייסו', 'שגם', 'שהדברים', 'שהוא', 'שהחברה', 'שהיה', 'שהיית', 'שהייתה', 'שהם', 'שוורד', 'שום', 'שונות', 'שותפים', 'שזה', 'שחושב', 'שחקן', 'שחשבתי', 'שיחה', 'שילוב', 'שיעלה', 'שיקדמו', 'שיר', 'שיש', 'שכבר', 'שכיף', 'שכן', 'של', 'שלא', 'שלה', 'שלהם', 'שלו', 'שלי', 'שלכם', 'שלנו', 'שם', 'שמה', 'שמונה', 'שמוע', 'שממש', 'שמסבירים', 'שמשמרת', 'שמתחברים', 'שמתכננים', 'שנאמרו', 'שנה', 'שני', 'שנים', 'שנמכרו', 'שנמצאת', 'שנקראת', 'שעובד', 'שעליה', 'שעליתם', 'שעריכה', 'שק', 'שקיבלה', 'שקשה', 'שראיתי', 'שרואה', 'שרוצים', 'שרשם', 'ששופט', 'ששלחת', 'שתיים', 'שתעני', 'שתצטרף', 'תגיד', 'תום', 'תחום', 'תחת', 'תנאים', 'תפילי', 'תקווה', 'תקציב', 'תרופה', 'תרופתי', 'תשמע', 'תתחבר']\n"
     ]
    }
   ],
   "source": [
    "def df_unique_words(df):\n",
    "    return sorted(list(set(' '.join(df).split())))\n",
    "print(df_unique_words(df['x']))\n",
    "# df['x'].str.split('\\s+', expand=True)\n",
    "#                   .stack()\n",
    "#                   .drop_duplicates()\n",
    "#                   .tolist()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['עכשיו', 'הוא', 'אומר', 'לי', 'זה', 'בסדר', 'הוא', 'אומר', 'ראיתי', 'את', 'המאמר', 'כל', 'הכבוד', 'לו', 'וכל', 'הכבוד', 'לך', 'ששלחת']\n",
      "['אהההה', 'עכשיו', 'הוא', 'אומר', 'לי', 'אההה', 'זה', 'זה', 'בסדר', 'הוא', 'אומר', 'ראיתי', 'את', 'המאמר', 'כל', 'הכבוד', 'לו', 'וכל', 'הכבוד', 'לך', 'לך', 'ששלחת']\n"
     ]
    }
   ],
   "source": [
    "a = df['x'].loc[8].split(' ')\n",
    "b = df['y'].loc[8].split(' ')\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m i,j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(a)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m:    \n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m b[j]:\n\u001b[1;32m      7\u001b[0m         aa\u001b[38;5;241m.\u001b[39mappend(a[i])\n\u001b[1;32m      8\u001b[0m         bb\u001b[38;5;241m.\u001b[39mappend(b[j])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "arr = []\n",
    "aa = []\n",
    "bb=[]\n",
    "i,j = len(a)-1,len(b)-1\n",
    "while i>=0 and j>=0:    \n",
    "    if a[i] == b[j]:\n",
    "        aa.append(a[i])\n",
    "        bb.append(b[j])\n",
    "        i-=1\n",
    "        j-=1\n",
    "    elif a[i] in b:\n",
    "        aa.append(a[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        aa.append(a[i])\n",
    "        bb.append(None)\n",
    "        bb.append(b[j])\n",
    "        aa.append(None)\n",
    "        \n",
    "        i-=1\n",
    "        j-=1\n",
    "        \n",
    "\n",
    "    \n",
    "    #     \n",
    "    #     bb.append(None)\n",
    "    #     j+=1   \n",
    "        \n",
    "#     # else:\n",
    "#     #     aa.append(a[i])\n",
    "#     #     bb.append(None)\n",
    "#     #     aa.append(a[i])\n",
    "#     #     bb.append(None)\n",
    "#     #     i+=1\n",
    "#     #     j+=1\n",
    "\n",
    "# for i,word in enumerate(a):\n",
    "#     print(word)\n",
    "#     print(i,np.where(b == word)[0])\n",
    "#     print('_'*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['הקבלה',\n",
       " 'והוא',\n",
       " 'לשמייו',\n",
       " None,\n",
       " 'נוסף',\n",
       " 'מובן',\n",
       " 'שיש',\n",
       " 'כותב',\n",
       " 'הוא',\n",
       " 'המרמבום',\n",
       " None,\n",
       " 'אבל',\n",
       " None,\n",
       " 'הקבלה',\n",
       " None]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['הקבלה',\n",
       " 'והוא',\n",
       " None,\n",
       " 'להשמיע',\n",
       " 'נוסף',\n",
       " 'מובן',\n",
       " 'שיש',\n",
       " 'כותב',\n",
       " 'הוא',\n",
       " None,\n",
       " 'ברמבם',\n",
       " None,\n",
       " 'גם',\n",
       " None,\n",
       " 'אבל']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_col(df,col,extra_cols=10):\n",
    "    # Split the 'x' column into separate columns\n",
    "    split_df = df[col].str.split(r'\\s+', expand=True)\n",
    "    # Rename the columns\n",
    "    columns = [f'{i+1}{col}' if i+1>9 else f'0{i+1}{col}' for i  in range(split_df.shape[1]+extra_cols)]\n",
    "    split_df.columns = columns[:split_df.shape[1]]\n",
    "    \n",
    "    # add extra empty columns for allowing to move columns later\n",
    "    for col in  columns[split_df.shape[1]:]:\n",
    "        split_df[col] = None  # You could use `None` instead of `pd.NA` if you prefer\n",
    "    # Join the new columns back to the original DataFrame\n",
    "    df = df.join(split_df)\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df = split_col(df.copy(),'x')\n",
    "df = split_col(df.copy(),'y')\n",
    "df = df[sorted(df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_row(row,from_col,name='x'):\n",
    "    ind = row.index\n",
    "    cols = [i for i in ind[row.notnull()] if i.endswith(name)][from_col-1:-1]\n",
    "    last = int(cols[-1].replace(name,''))+1\n",
    "    cols += [f'{last}{name}' if last>9 else f'0{last}{name}']\n",
    "    row[cols[1:]] = row[cols[:-1]] \n",
    "    row[cols[0]] = None \n",
    "    \n",
    "    \n",
    "    # row = row.append(pd.Series([None]*(len(row),len(from_col)-len(row)), index=from_col)\n",
    "    return row\n",
    "    \n",
    "# move_row(row=df.loc[0],from_col=1,to_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01x                                                      אבל\n",
      "01y                                                      אבל\n",
      "02x                                                  המרמבום\n",
      "02y                                                       גם\n",
      "03x                                                      הוא\n",
      "03y                                                    ברמבם\n",
      "04x                                                     כותב\n",
      "04y                                                      הוא\n",
      "05x                                                      שיש\n",
      "05y                                                     כותב\n",
      "06x                                                     מובן\n",
      "06y                                                      שיש\n",
      "07x                                                     נוסף\n",
      "07y                                                     מובן\n",
      "08x                                                   לשמייו\n",
      "08y                                                     נוסף\n",
      "09x                                                     והוא\n",
      "09y                                                   להשמיע\n",
      "10x                                                    הקבלה\n",
      "10y                                                     והוא\n",
      "11x                                                     None\n",
      "11y                                                    הקבלה\n",
      "12x                                                     None\n",
      "12y                                                     None\n",
      "13x                                                     None\n",
      "13y                                                     None\n",
      "14x                                                     None\n",
      "14y                                                     None\n",
      "15x                                                     None\n",
      "15y                                                     None\n",
      "16x                                                     None\n",
      "16y                                                     None\n",
      "17x                                                     None\n",
      "17y                                                     None\n",
      "18x                                                     None\n",
      "18y                                                     None\n",
      "19x                                                     None\n",
      "19y                                                     None\n",
      "20x                                                     None\n",
      "20y                                                     None\n",
      "21x                                                     None\n",
      "21y                                                     None\n",
      "22x                                                     None\n",
      "22y                                                     None\n",
      "23x                                                     None\n",
      "23y                                                     None\n",
      "24x                                                     None\n",
      "24y                                                     None\n",
      "25x                                                     None\n",
      "25y                                                     None\n",
      "26x                                                     None\n",
      "26y                                                     None\n",
      "27x                                                     None\n",
      "27y                                                     None\n",
      "28y                                                     None\n",
      "29y                                                     None\n",
      "30y                                                     None\n",
      "31y                                                     None\n",
      "x          אבל המרמבום הוא כותב שיש מובן נוסף לשמייו והוא...\n",
      "x_count                                                   10\n",
      "x_orig     אבל המרמבום הוא כותב שיש מובן נוסף לשמייו והוא...\n",
      "y          אבל גם ברמבם הוא כותב שיש מובן נוסף להשמיע והו...\n",
      "y_count                                                   11\n",
      "y_orig     אבל גם ברמב\"ם הוא כותב שיש מובן נוסף להשמיע וה...\n",
      "Name: 0, dtype: object\n",
      "01x                                                      אבל\n",
      "01y                                                      אבל\n",
      "02x                                                     None\n",
      "02y                                                       גם\n",
      "03x                                                  המרמבום\n",
      "03y                                                    ברמבם\n",
      "04x                                                      הוא\n",
      "04y                                                      הוא\n",
      "05x                                                     כותב\n",
      "05y                                                     כותב\n",
      "06x                                                      שיש\n",
      "06y                                                      שיש\n",
      "07x                                                     מובן\n",
      "07y                                                     מובן\n",
      "08x                                                     נוסף\n",
      "08y                                                     נוסף\n",
      "09x                                                   לשמייו\n",
      "09y                                                   להשמיע\n",
      "10x                                                     והוא\n",
      "10y                                                     והוא\n",
      "11x                                                    הקבלה\n",
      "11y                                                    הקבלה\n",
      "12x                                                     None\n",
      "12y                                                     None\n",
      "13x                                                     None\n",
      "13y                                                     None\n",
      "14x                                                     None\n",
      "14y                                                     None\n",
      "15x                                                     None\n",
      "15y                                                     None\n",
      "16x                                                     None\n",
      "16y                                                     None\n",
      "17x                                                     None\n",
      "17y                                                     None\n",
      "18x                                                     None\n",
      "18y                                                     None\n",
      "19x                                                     None\n",
      "19y                                                     None\n",
      "20x                                                     None\n",
      "20y                                                     None\n",
      "21x                                                     None\n",
      "21y                                                     None\n",
      "22x                                                     None\n",
      "22y                                                     None\n",
      "23x                                                     None\n",
      "23y                                                     None\n",
      "24x                                                     None\n",
      "24y                                                     None\n",
      "25x                                                     None\n",
      "25y                                                     None\n",
      "26x                                                     None\n",
      "26y                                                     None\n",
      "27x                                                     None\n",
      "27y                                                     None\n",
      "28y                                                     None\n",
      "29y                                                     None\n",
      "30y                                                     None\n",
      "31y                                                     None\n",
      "x          אבל המרמבום הוא כותב שיש מובן נוסף לשמייו והוא...\n",
      "x_count                                                   10\n",
      "x_orig     אבל המרמבום הוא כותב שיש מובן נוסף לשמייו והוא...\n",
      "y          אבל גם ברמבם הוא כותב שיש מובן נוסף להשמיע והו...\n",
      "y_count                                                   11\n",
      "y_orig     אבל גם ברמב\"ם הוא כותב שיש מובן נוסף להשמיע וה...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0])\n",
    "print(move_row(row=df.loc[0].copy(),from_col=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 12, 5, 13]\n",
      "[1, 0, 0, 0]\n",
      "Pearson correlation coefficient: 0.9034396182886775\n"
     ]
    }
   ],
   "source": [
    "def decode_word(word):\n",
    "    # Decode the Hebrew words - drop the first 1488 unicode value of aleph letter\n",
    "    return [ord(char)-1488 for char in word]\n",
    "def decode_pair(word1,word2):\n",
    "    vector1 = decode_word(word1)  # Example vector for \"example\"\n",
    "    vector2 = decode_word(word2)  # Example vector for \"exemplary\"\n",
    "    LEN = max(len(vector1),len(vector2))\n",
    "    vector1 += [0]*(LEN-len(vector1))\n",
    "    vector2 += [0]*(LEN-len(vector2))\n",
    "    print(vector1),print(vector2)\n",
    "    correlation = pearsonr(vector1, vector2)[0]\n",
    "    print(f\"Pearson correlation coefficient: {correlation}\")\n",
    "    return vector1,vector2\n",
    "vector1,vector2 = decode_pair('שלום','בא')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient: 0.9034396182886775\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# Example phonetic feature vectors\n",
    "# In practice, these would be derived from a more complex phonetic analysis\n",
    "# vector1 = decode_word('הקבלה')  # Example vector for \"example\"\n",
    "# vector2 = decode_word('הקבלה')  # Example vector for \"exemplary\"\n",
    "\n",
    "# Compute Pearson correlation coefficient\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count number of words in each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['אבל', 'המרמבום', 'הוא', 'כותב', 'שיש', 'מובן', 'נוסף', 'לשמייו', 'והוא', 'הקבלה.', 'נגיד,', 'קהילת', 'ישראל,', 'צרפת,', 'ספרד', \"וכו'.\", 'בעיקרון', 'זה', 'פשוט,', 'אין', 'סיבה', 'שאתה', 'תתחבר', 'למיטאפ', 'שלא', 'מדבר', 'אליך,', 'שהוא', 'תחום', 'מעניין', 'לא', 'רלוונטי.', 'למה', 'מה', 'כואב', 'לנו', 'לקוות', 'ולמקווי', 'חיפה', 'נקווה.', 'מי', 'אחד', 'לאחד,', 'מכל', 'לכל', 'אחד.', 'בתיבת', 'הטקסט', 'שנמצאת', 'בימין', 'המסך.', 'שאין', 'לך', 'יכולת', 'לתפוס', 'את', 'הקנה', 'מידע', 'שלהם?', 'חוקי', 'פארקינגסון.', '\\u202bובמה', 'שאני', 'אומר', 'היום,', 'היום', 'גם...', 'עכשיו', 'לי,', 'בסדר,', 'ראיתי', 'המאמר,', 'כל', 'הכבוד', 'לו', 'וכל', 'ששלחת.', 'תגיד', 'לדי', 'שרשם', 'דברים,', 'רוצה...', 'ומטרות', 'שונות', 'בתחום', 'ההוראה,', 'גם', 'תקציב.', 'זאת', 'הייתה,', 'אני', 'חושב,', 'קודם', 'הפעם', 'הראשונה', 'שלי', 'שראיתי', 'בכלל', 'מחבל', 'מול', 'העיניים.', 'רלוונטי,', 'שיקדמו', 'אותך.', '\\u202bאו', 'שנאמרו', 'שהדברים', '\\u202bממש', 'היו', 'קשים', 'לבחינתי', 'מוסרית.', 'אותי', 'במקום', 'של', 'הדיגיטציה', 'שלה.', 'תום', 'פרידמן,', 'הספר', 'הראשון', 'כתב.', 'באחד', 'הדברים', 'שאנחנו', 'עושים', 'במרכז', 'הישראלי', 'להתמוקד,', 'מלמדים', 'דברים', 'שמתחברים', 'אל', 'הלב', 'כי...', 'הטראנס', 'נפגשת', 'הרבה', 'עם', 'רופאים', 'ורופאות,', 'בין', 'אם', 'על', 'רקע', 'טיפולי', 'התאמה', 'מגדרית', 'ובין', 'לצרכים', 'אחרים.', 'באמת', 'מטורף,', 'אף', 'פעם', 'כלים.', 'אול', 'דה', 'פאריש', 'מרובה', 'פאריש,', 'מכיוון', 'שבעברית', 'פשוטה...', 'לגיל,', 'לעוצמו,', 'אומרת,', 'ילד', 'שקשה', 'להיפרד', 'מאימא', 'שלו', 'ולהיכנס', 'אליך', 'לבדיקה.', 'ואז', 'בדבר', 'בשפה', 'שלה', 'היא', 'באותה', 'מידה', 'יכולה', 'להגיד', 'לי.', '\\u202bלא,', 'לא,', 'מגניב.', '\\u202bמה', 'מנסה', 'ש...', 'טיפולים', 'וכימותים', 'פרבולים', 'ועוד', 'פשוט...', 'סוגיה', 'תנאים', 'סניטריים,', 'רוצה', 'ללכת', 'לבעיה', 'האמיתית', 'שלנו', 'שעליה', 'צריך', 'לחשוב.', 'כל,', 'בצהל', 'יש', 'פקודת', 'השילוב', 'הראוי.', 'פקודה', 'כזאת.', 'עדיין', 'צעיר', 'רק', '25.', 'אוקיי,', 'וזה', 'גורם', 'לך,', 'משהו', 'פנימי.', 'בזמן', 'משחק,', 'המאמן', 'אומר,', 'תשמע,', 'יונתן,', 'שתצטרף', 'מקו', 'שני,', 'ואני', 'שתעני', 'הכדור', 'יותר', 'מהר,', 'מקשיב', 'משם', 'זיין.', 'למשל', 'צורת', 'הקשר', 'או', 'ה...', 'להיות', 'גדול', 'וגיבור', 'ולעצב', 'העולם.', 'רמת', 'גן,', 'כאילו', 'ראש', 'העין', 'לסאוף', 'קרוליינה.', '\\u202bהוקחינו', 'חובה', 'עד', 'גיל', '12,', '\\u202bאחר', 'כך', '3,', '\\u202bוזה', '14.', 'עקותיות', 'בעיות', 'משנות', 'מציאות.', 'העובדים', 'מיליו', 'שהם', 'עובדים', 'מאוד', 'קשה', 'שהחברה', 'הזאת.', \"חבר'ה\", 'הקונגלומרטים,', 'אתה', 'יודע.', 'בעייתי', 'מבחינה', 'טכנית', 'כי', 'שם', 'עומקים', '3,000', 'מטר', 'וצריך', 'להניח', 'צינור', 'פשוט.', 'באותו', 'יום,', 'בחינם', 'לדעתי,', 'מהם,', 'מהם', 'בא', 'בחינם,', 'אבדולאי', 'שק,', 'חתולבה,', 'שמוע', 'מלא.', 'שני', 'בניים', 'זרים', 'יפה', 'בעברות,', 'חושב', 'שעליתם', 'ליגת', 'אלפות,', 'אמרתי', 'הסגל', 'הזה', 'שלכם,', 'לוקחים', 'אליפות,', 'מצב,', 'וצריכים', '14', 'קנים,', '2', 'מבטא.', 'תקווה', 'נראה', 'לי', 'שגם', 'הייתה', 'מבוססת', 'באיזשהו', 'מקום', 'מקאבי', 'שהייתה', 'אחרי', 'שקיבלה', 'שתיים', 'מהצד', 'המעליב', 'מראה', 'בוא', 'נודה', 'באמת.', 'כתבו', 'בוודאי', 'היה...', 'ובדוקטורט,', 'להזכיר', 'היה', 'במפגשים', 'הקודמים,', 'אז', 'לנו...', 'הולך', 'לשרת', 'אתכם', 'למשך', 'איזה', 'זמן.', 'דוגמא', 'אחת,', 'קונספציה', 'מסוכנת?', 'בעצם', 'השלוש', 'מאות', 'וחמישה', 'עשר', 'האלה', 'בנויים.', 'אשמנת', 'יתר,', 'אנטיביוטיקה', 'כזאת,', 'יכול', 'להתלהלות', 'כמה', 'סיבות,', 'תרופה', 'שנקראת...', 'דבר', 'שאנשים', 'מתעניינים', 'בו.', 'אסכים', 'איתך', 'לגמרי,', 'ישר', 'לסטרימינג', 'מעולה.', 'לפחות', '3-4', 'שנים', 'כבר', 'אכל', 'בתקופה', 'אמרת', 'ודיאקת', 'וגם', 'אתמול', 'כתבת', 'בצוויצר.', 'עוד', 'משחק', 'כמו', 'שיעלה', 'הליכון', 'מצדי.', 'שבר', 'הפרדיגמה', 'והיא', 'התחלתה', 'ב...', 'מרגש', 'והרבה', 'משמעותי', 'ממה', 'שחשבתי', 'יהיה.', 'בניגוד', 'למוות', 'בסוף', 'חיים.', 'נושאים', 'שהיית', 'לחדד,', 'שמסבירים', 'אוהב', 'להעביר?', 'אמרתי,', 'מורכבות,', 'כן.', 'כן,', 'לחנך', 'אנשים', 'לפשטנות,', 'הדבר', 'המרכזי', 'והיחיד.', 'אוקיי.', 'מבחינתך', 'שבאמת...', 'מצב', 'הארים', 'שלנו,', 'אנחנו', 'חיים', 'בארים', 'שכיף', 'לחיות', 'בהם,', 'האם', 'המתכננים,', 'מתכנני', 'הארים,', 'הדריכלים', 'עבודתם', 'נאמנה,', 'באופן', 'כזה', 'שמה', 'שמתכננים', 'אוהבים,', 'והם', 'יוצרים', 'ארים', 'גם.', 'אותו', 'דבר,', 'ויהיה', 'הם', 'יכולים', 'ליהנות', 'פה', 'משוויון', 'זכויות', 'אזרחי', 'גמור.', 'מקווה', 'במפגש', 'לחזור', 'לכם', 'זמן', 'לימוד', 'למדתי', 'מניסיון', 'דרך', 'עליהם', 'מאלה', 'בעונה', 'הראשונה,', 'המלצה', 'האישית', 'בואו', 'נתחיל', 'באמת,', 'הבעיה,', 'חושבת', 'שוורד', 'חוותה', 'אותה,', 'שעריכה', 'לשונית', 'תחום...', 'רואה', 'איזושהי', 'אפליה', 'חזקה,', 'ובסך', 'הכול', 'שבאמת', 'רוצים', 'ובאמת', 'מפגינים', 'זה.', 'ניהלו', 'המאזנים', 'שלהם', 'בצורה', 'טובה', 'ומגוונת', 'ומפוזרת?', 'ירום', 'הודו', 'והבחר', 'בך', 'לסרט', 'לסדרה', 'שלו.', 'הטיסה?', 'הטיסה.', 'מפחיד,', 'מטור', 'סייר', 'בס', 'רחב', 'גוף,', 'וכולם', 'ככה', 'מרחפים', 'ונהנים.', 'מלאה', 'בנוזל', 'ומאוד', 'לנתח', 'אותה', 'שמשמרת', 'שכן', 'נמצא', 'תחת', 'טיפול', 'תרופתי,', 'שאולי', 'תרופתי.', 'להודות', 'שיחה', 'סופר', 'מעניינת.', 'פרפורמנס', 'סטארט-אפ,', 'מיני', 'ליגל,', 'כאלה,', 'רץ', 'ואתה', 'מדויק.', 'עדיפים', 'מישהו', 'אחר.', 'ליצור', 'סרטונים', 'אינטראקטיביים,', 'שזה', 'שילוב', 'סרטים.', 'נמצאים', 'בהתחלה.', 'ויודעים', 'המזונות', 'בערך,', 'בסדר?', 'השבק,', 'פתאום', 'לעצמי,', 'כאן', 'לקח', 'רחב.', 'היית', 'לעבוד', 'בעבודה', 'מאייפת', 'והיית', 'להתרכז', 'בלימודים.', 'מנוחה', 'ומתעסק', 'פחות', 'איך', \"הג'קט\", 'ואיך', 'העיניים', 'נראות.', '\\u202bוהאינטרס', 'המקומי,', 'די', 'ביטוי,', '\\u202bבאה.', 'הבנה', 'פעילות', 'חישובית', 'בעולם', 'קליפת', 'המוח,', 'קורטקס.', 'האתגר', 'הפיזיקלי', 'בידוד.', 'שיר', 'מקאי', 'בליגה,', 'כשזה', 'עונה', 'אחת.', 'אין,', 'בסודיקה.', 'המטומטם', 'אמרו', 'שרוצים,', 'שחקן', 'ילדים,', 'אוקיי?', 'כאילו...', 'המחנה', 'השמאל', 'מתעורר', 'קצת', 'מוקדם', 'לסיפור', 'בערך', 'סביב', '2019', 'כאשר...', 'בוקר,', 'יום', 'ראשון,', 'שמונה', 'עשר.', 'האזין', 'קבוע', 'במייקל', 'נועה', 'בעצמו', 'בשביל', 'היסטוריון', 'ולהכיר,', 'ולא', 'אנכרוניסט.', 'ואת', 'לבצע', 'איזשהו...', 'לחשוד,', 'טוב,', 'עוף', 'מפה.', 'ובגרמניה', 'קר', 'בחורף,', 'והחורף', 'הולכים', 'לחוות', 'כנראה...', '\\u202bבלי', 'שום', 'קשר', 'לקורונה.', 'שנמכרו', 'ממש', 'מזמן', 'לחברת', 'וויקס,', 'חברת', 'פניית', 'האתרים,', 'שבעצם', 'מתרחבת', 'לתחומי', 'מצד', 'נותן', 'לחילופין,', 'אמר,', '\\u202bזה', 'התעודת', 'ביטוח', 'לבנון,', 'כן?', '\\u202bמה,', 'אתם', '2006?', 'נעים.', 'נכון', 'ההבדל', 'החוזה', 'לחוזה', 'צריכים', 'להישאר', '18', 'שנה.', 'מת', 'עליו,', 'הקבוצה', 'הזאתי', 'והיה', 'כיף', 'לדבר', 'איתו,', 'השתלטתי', 'לסיחה', 'בגלל', 'שהיה', 'מעניין.', 'כבר,', 'אפילו', 'חייב,', 'מתכונים', 'עוזר', 'שכבר', 'בדקו', 'וטעו', 'ואומרים', 'הנה', 'שעובד.', 'כבוד', 'גזרה.', 'שממש', 'אקסלרציה', 'בארץ', 'בחור.', 'רציתי', 'סתם', 'קורה', 'בדיון', 'ששופט', 'יורד', 'ל...', 'רבים', 'מאלף', 'ומתיים', 'המגורשים', 'לטבריה', 'מסתובב', 'ככה,', 'קטע', 'גרביים', 'לבנות,', 'ספורט,', 'מתוחות', 'למעלה,', 'לגמרי.', 'קפקפים.', 'שותפים', \"הג'י\", 'פיז,', 'שגייסו', 'הכסף', 'מהאל', 'פיז.', 'היחיד', 'שחושב', 'פייט', 'קלאב', 'עכשיו,', 'בחדר', 'שרואה', 'סצנה', 'מפייט', 'קלאב,', 'ליד', 'תפילי', 'מוח,', 'התמודדות,', 'מכירה', 'הרפרנס', 'הרי', 'לפייט', 'קלאב?', 'יודעת,', 'סיפרת', 'אחייד', 'שלי,', 'כן', 'מתעסק', 'בכל', 'המשחקים', 'וזה,', 'מבינה', 'חדרים,', 'סר', 'נפוסם', 'משנת', '2000,', 'למויאל', 'לזה', 'לעבור', 'טורקאנה.', 'טיול', 'בפני', 'עצמו,', 'אבל...', 'להשפיע', 'העבודה', 'הממשלה', 'במאה', 'ה-21,', 'ואיפה', 'אחזור', 'עליה', 'הילדים', 'ושיתפתי', 'איתם', 'בסיפור', 'והסברתי', 'להם']\n"
     ]
    }
   ],
   "source": [
    "print (df['x'].str.replace(r'''[\\-\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\_\\+\\[\\]\\;\\'\\.\\,\\/\\{\\}\\:\\\"\\<\\>\\?\\|]''','')\n",
    "                #   .replace(r'[\\  \\   \\]',' ')\n",
    "                  .str\n",
    "                  .lower()\n",
    "                  .str\n",
    "                  .split('\\s+', expand=True)\n",
    "                  .stack()\n",
    "                  .drop_duplicates()\n",
    "                  .tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['y_count'] = df['y'].apply(lambda x: len(str(x).split()))\n",
    "remove [',','  '] in x\n",
    "for  \n",
    "df['x'] = df['x'].apply(lambda x: x.replace(',',''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x_count</th>\n",
       "      <th>y_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>אבל המרמבום הוא כותב שיש מובן נוסף לשמייו והוא...</td>\n",
       "      <td>אבל גם ברמב\"ם הוא כותב שיש מובן נוסף להשמיע וה...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>נגיד, קהילת ישראל, קהילת צרפת, ספרד וכו'.</td>\n",
       "      <td>נגיד, קהילת ישראל, קהילת צרפת, ספרד וכו'.</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>בעיקרון זה פשוט, אין סיבה שאתה תתחבר למיטאפ של...</td>\n",
       "      <td>בעיקרון זה פשוט, אין סיבה שאתה תתחבר למיטאפ של...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>למה לא מה מה מה כואב לנו לקוות ולמקווי חיפה נק...</td>\n",
       "      <td>בוא נקווה למה לא מה מה מה כואב לנו לקוות ולמכב...</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>מי אחד לאחד, מי אחד מכל אחד לכל אחד.</td>\n",
       "      <td>מי אחד לאחד, מי אחד מכל אחד לכל אחד.</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x  \\\n",
       "0  אבל המרמבום הוא כותב שיש מובן נוסף לשמייו והוא...   \n",
       "1          נגיד, קהילת ישראל, קהילת צרפת, ספרד וכו'.   \n",
       "2  בעיקרון זה פשוט, אין סיבה שאתה תתחבר למיטאפ של...   \n",
       "3  למה לא מה מה מה כואב לנו לקוות ולמקווי חיפה נק...   \n",
       "4               מי אחד לאחד, מי אחד מכל אחד לכל אחד.   \n",
       "\n",
       "                                                   y  x_count  y_count  \n",
       "0  אבל גם ברמב\"ם הוא כותב שיש מובן נוסף להשמיע וה...       10       11  \n",
       "1          נגיד, קהילת ישראל, קהילת צרפת, ספרד וכו'.        7        7  \n",
       "2  בעיקרון זה פשוט, אין סיבה שאתה תתחבר למיטאפ של...       16       16  \n",
       "3  בוא נקווה למה לא מה מה מה כואב לנו לקוות ולמכב...       11       13  \n",
       "4               מי אחד לאחד, מי אחד מכל אחד לכל אחד.        9        9  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
