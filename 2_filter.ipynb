{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_dir: /home/yishai/Desktop/ivrit_ai_llm/app\n",
      "data_dir: /home/yishai/Desktop/ivrit_ai_llm/data\n",
      "golden_data_dir: /home/yishai/Desktop/ivrit_ai_llm/golden_data\n"
     ]
    }
   ],
   "source": [
    "from app.dotenv import base_dir, data_dir,golden_data_dir\n",
    "# from app.model.model import  Model\n",
    "# import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)\n",
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "# print('dotenv params:', {os.getenv('PARAM1')})\n",
    "print('base_dir:', base_dir)\n",
    "print('data_dir:', data_dir)\n",
    "print('golden_data_dir:', golden_data_dir)\n",
    "\n",
    "# model = Model()\n",
    "# print('model:', model)\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avg_logprob - the average log probability of the tokens in the transcription\n",
    "estimating the confidence of the transcription. Lower values (more negative) indicate lower confidence, while values closer to zero indicate higher confidence in the transcription.\n",
    "Values generally range between -1.0 and 0, below -0.5 is suspected below -1 is very suspected\n",
    "\n",
    "\n",
    "no_speech_prob - probability is high (close to 1), it suggests that the model believes the segment is likely silence or background noise, rather than actual speech. This can be useful for filtering out non-speech parts.\n",
    "Values range from 0 to 1, where 0 indicates a high likelihood that the segment contains speech, and 1 indicates a high probability that the segment contains no speech.\n",
    "\n",
    "compression_ratio - measure of how much the output text has been \"compressed\" compared to the input audio in terms of information content. Higher values might indicate potential issues, such as long stretches of repeated text or overly verbose output.\n",
    "Typically ranges from 1.0 to 2.5. A value of 1.0 means that the transcription is roughly equal in length to the original audio input, while higher values indicate more compression (shorter transcribed text relative to the audio duration).\n",
    "\n",
    "Suggested Workflow:\n",
    "\n",
    "Filter Low Confidence Segments: Identify segments with a low avg_logprob or a high no_speech_prob and prioritize these for refinement by the LLM.\n",
    "\n",
    "Fix Repetitive or Garbled Transcriptions: Use the compression_ratio to detect where the transcribed text might be problematic (too verbose, repeated words) and ask the LLM to clean up these sections.\n",
    "\n",
    "Time-based Post-Processing: Use the start and end timestamps to make sure the LLM processes segments in the right sequence, especially if you are breaking up the transcription for batch processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load df from file\n",
    "\n",
    "1. add wanted attribute columns & remove nulls  \n",
    "2. drop columns\n",
    "3. remove formatting chracters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: sentence, dtype: object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{golden_data_dir}/crowd-transcribe-v4-enriched.csv')\n",
    "ind = ~df['attrs'].isnull()\n",
    "df.loc[ind,'attrs'] = df.loc[ind,'attrs'].apply(lambda x: json.loads(x))\n",
    "df = df.loc[((~df['sentence'].isnull())*(~df['orig_sentence'].isnull()))]\n",
    "# verify nulls are dropped\n",
    "df['sentence'].loc[(~(~df['sentence'].isnull())*(~df['orig_sentence'].isnull()))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111858\n",
      "1901\n",
      "5307\n"
     ]
    }
   ],
   "source": [
    "vals = {'avg_logprob':-0.5,'no_speech_prob':0.5,'compression_ratio':2.0}\n",
    "inds = {}\n",
    "for key,value in vals.items():\n",
    "    df[key] = value\n",
    "    # df.loc[0,'attrs']['segments'][0]['avg_logprob']\n",
    "    df[key] = None\n",
    "    df.loc[ind,key] = df.loc[ind,'attrs'].apply( lambda x:  x['segments'][0][key] )\n",
    "    # data = df.loc[ind,key].loc[df.loc[ind,key]>value]\n",
    "    inds[key] = (df.loc[ind,key].loc[df.loc[ind,key]>value].index,df.loc[ind,key].loc[df.loc[ind,key]<value].index)    \n",
    "    print(len(inds[key][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['orig_sentence', 'sentence', 'source', 'episode', 'avg_logprob',\n",
       "       'no_speech_prob', 'compression_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['attrs','is_retranscribe','uuid'],inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove chracters function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_chars(df: DataFrame,columns,remove_ords =[],remove_chars =[],replace_char = '') -> DataFrame:\n",
    "\n",
    "    def replace_chars_from_col(col,in_chars,replace_char = '',is_ord = False):\n",
    "        for ch in in_chars:\n",
    "            if is_ord:\n",
    "                col = col.str.replace(chr(ch),replace_char)\n",
    "            else:\n",
    "                col = col.str.replace(ch,replace_char)\n",
    "            \n",
    "        # for ch in ['  ','-']:\n",
    "        #     col = col.str.replace(ch,' ')\n",
    "        return col\n",
    "\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].str.lower()\n",
    "        df[col] = replace_chars_from_col(df[col].copy(),remove_ords,replace_char = replace_char,is_ord = True)\n",
    "\n",
    "        df[col] = replace_chars_from_col(df[col].copy(),remove_chars,replace_char = replace_char,is_ord = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove error characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing chars and their ords\n",
      " ,\t!,\t\",\t$,\t%,\t&,\t',\t(,\t),\t+,\t,,\t-,\t.,\t0,\t1,\t2,\t3,\t4,\t5,\t6,\t7,\t8,\t9,\t:,\t=,\t?,\t[,\t],\ta,\tb,\tc,\td,\te,\tf,\tg,\th,\ti,\tj,\tk,\tl,\tm,\tn,\to,\tp,\tq,\tr,\ts,\tt,\tu,\tv,\tw,\tx,\ty,\tz,\tż,\tα,\tζ,\tμ,\tο,\tπ,\tа,\tб,\tв,\tг,\tд,\tе,\tи,\tк,\tл,\tо,\tп,\tр,\tс,\tу,\tш,\tь,\tא,\tב,\tג,\tד,\tה,\tו,\tז,\tח,\tט,\tי,\tך,\tכ,\tל,\tם,\tמ,\tן,\tנ,\tס,\tע,\tף,\tפ,\tץ,\tצ,\tק,\tר,\tש,\tת,\n",
      "32,\t33,\t34,\t36,\t37,\t38,\t39,\t40,\t41,\t43,\t44,\t45,\t46,\t48,\t49,\t50,\t51,\t52,\t53,\t54,\t55,\t56,\t57,\t58,\t61,\t63,\t91,\t93,\t97,\t98,\t99,\t100,\t101,\t102,\t103,\t104,\t105,\t106,\t107,\t108,\t109,\t110,\t111,\t112,\t113,\t114,\t115,\t116,\t117,\t118,\t119,\t120,\t121,\t122,\t380,\t945,\t950,\t956,\t959,\t960,\t1072,\t1073,\t1074,\t1075,\t1076,\t1077,\t1080,\t1082,\t1083,\t1086,\t1087,\t1088,\t1089,\t1091,\t1096,\t1100,\t1488,\t1489,\t1490,\t1491,\t1492,\t1493,\t1494,\t1495,\t1496,\t1497,\t1498,\t1499,\t1500,\t1501,\t1502,\t1503,\t1504,\t1505,\t1506,\t1507,\t1508,\t1509,\t1510,\t1511,\t1512,\t1513,\t1514,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def print_existing_unique_chars(cols):\n",
    "    \n",
    "    def cols_unique_characters(cols,print_ord = False):\n",
    "        uniq_chars = sorted(set(''.join(''.join(col) for col in cols)))\n",
    "        if print_ord:\n",
    "            return [ord(ch) for ch in uniq_chars]\n",
    "        return uniq_chars\n",
    "    \n",
    "    uniq1 = cols_unique_characters(cols)\n",
    "    uniq2 = cols_unique_characters(cols,print_ord = True)\n",
    "    print ('existing chars and their ords') \n",
    "    print('\\t'.join([str(x)+',' for x in uniq1]))\n",
    "    print('\\t'.join([str(x)+',' for x in uniq2]))\n",
    "    \n",
    "\n",
    "# error characters:\n",
    "\n",
    "error_ords =[]\n",
    "error_ords1 = [1470,1468,1465,1463,1462,1460,1099,1464,47,1523,\t1524,\t1575,\t1576,\t1578,\t1582,\t1585,\t1603,\t1606,\t8211,\t8212,\t8230,\t9834,\t9835,\t20126,\t21478,\t24555,\t26126,\t26449,\t27794,\t29978,\t35201,\t38590,\t40636,\t46988,\t47673,\t49324,\t49900,\t50508,\t50520,\t50612,\t50880,\t51032,\t51060,\t65533,]\n",
    "error_ords += error_ords1\n",
    "# # latin letters - might be usefull to keep\n",
    "# remove_ords2 = [380,\t945,\t950,\t956,\t959,\t960,\t1072,\t1073,\t1074,\t1075,\t1076,\t1077,\t1080,\t1082,\t1083,\t1086,\t1087,\t1088,\t1089,\t1091,\t1096,\t1100]\n",
    "# remove_ords += remove_ords2\n",
    "\n",
    "error_chars = ['\\u202b','\\u200f','\\u200e','\\n']\n",
    "\n",
    "   \n",
    "df = remove_chars(df.copy(),columns = ['orig_sentence','sentence'],\n",
    "                  remove_ords = error_ords,remove_chars = error_chars,\n",
    "                  replace_char = '')\n",
    "\n",
    "df = remove_chars(df.copy(),columns = ['orig_sentence','sentence'],\n",
    "                  remove_chars = ['  '], replace_char = ' ')        \n",
    "print_existing_unique_chars([df['orig_sentence'].copy(),df['orig_sentence'].copy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in ['orig_sentence','sentence']:\n",
    "    ind = df[col].str.len()==0\n",
    "    df = df.loc[~ind]   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### baseline results - filter out samples without mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WER - word error rate\n",
    "\n",
    "calculate how well the hypothesis (orig_sentence) matches the correct reference (sentence)\n",
    "\n",
    "WER = (S+D+I)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jiwer import wer\n",
    "\n",
    "# reference = \"the correct translation\"\n",
    "# hypothesis = \"your corrected sentence\"\n",
    "\n",
    "# error_rate = wer(reference, hypothesis)\n",
    "# print(f\"Word Error Rate: {error_rate}\")\n",
    "import jiwer\n",
    "\n",
    "\n",
    "transforms = jiwer.Compose(\n",
    "    [\n",
    "        jiwer.ExpandCommonEnglishContractions(),\n",
    "        jiwer.RemoveEmptyStrings(),\n",
    "        jiwer.ToLowerCase(),\n",
    "        jiwer.RemoveMultipleSpaces(),\n",
    "        jiwer.Strip(),\n",
    "        jiwer.RemovePunctuation(),\n",
    "        jiwer.ReduceToListOfListOfWords(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "wer = df.apply(lambda x: jiwer.wer(x['sentence'],x['orig_sentence'],\n",
    "                                   truth_transform=transforms, hypothesis_transform=transforms,\n",
    "                                   )\n",
    "                     ,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero wer: 78808  percentage: 0.50085479862978\n"
     ]
    }
   ],
   "source": [
    "LEN = len(df.loc[df['wer']==0.0])\n",
    "print('zero wer:',LEN,' percentage:',LEN/len(df))\n",
    "# zero wer: 78808  percentage: 0.50085479862978\n",
    "\n",
    "\n",
    "df = df.loc[df['wer']>0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orig_sentence', 'sentence', 'source', 'episode', 'avg_logprob', 'no_speech_prob', 'compression_ratio']\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(drop=True,inplace=True)\n",
    "# for col in df.columns:\n",
    "#     if 'float' in str(df[col].dtype):\n",
    "#         df[col] = df[col].astype(float)\n",
    "#     if 'int' in str(df[col].dtype):\n",
    "#         df[col] = df[col].astype(int)\n",
    "print([col for col in df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(f'{data_dir}/crowd-transcribe-v4-enriched-1.csv', index=False)\n",
    "# df1 = pd.read_csv(f'{data_dir}/crowd-transcribe-v4-enriched-1.csv')\n",
    "\n",
    "\n",
    "# ddf = df[~(df.isnull().sum(axis=1).astype(bool))].copy()\n",
    "# ddf1 = df1[~(df1.isnull().sum(axis=1).astype(bool))].copy()\n",
    "# if (ddf1==ddf).all().all():\n",
    "    \n",
    "#     print('df and df1 are equal')\n",
    "#     del df1,ddf,ddf1#df,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'numpy.float64'>]\n",
      "[<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>, <class 'numpy.float64'>]\n"
     ]
    }
   ],
   "source": [
    "print([type(df[col].loc[0]) for col in df.columns])\n",
    "print([type(df1[col].loc[0]) for col in df.columns])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
